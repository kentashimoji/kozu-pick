#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
src/file_processors.py - ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†å°‚ç”¨ã‚¯ãƒ©ã‚¹ï¼ˆå®Œå…¨ä¿®æ­£ç‰ˆï¼‰
ZIPãƒ•ã‚¡ã‚¤ãƒ«å†…ã®Shapefileå‡¦ç†ã«å¯¾å¿œ
"""

import streamlit as st
import pandas as pd
import geopandas as gpd
import zipfile
import io
import tempfile
import os
from typing import Dict, List, Any, Optional

class FileProcessor:
    """ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã®ãƒ¡ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        self.supported_extensions = ['.zip', '.csv', '.xlsx', '.xls', '.shp', '.kml', '.geojson']
        self.shapefile_extensions = ['.shp', '.dbf', '.shx', '.prj', '.cpg']

    def process_file(self, file_content: bytes, file_name: str, file_extension: str) -> bool:
        """ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã®ãƒ¡ã‚¤ãƒ³ãƒ¡ã‚½ãƒƒãƒ‰"""
        try:
            st.write(f"ğŸ“ å‡¦ç†é–‹å§‹: {file_name} ({file_extension})")
            
            if file_extension == '.zip':
                return self._process_zip_file(file_content, file_name)
            elif file_extension in ['.csv', '.xlsx', '.xls']:
                return self._process_data_file(file_content, file_extension)
            elif file_extension == '.shp':
                return self._process_shapefile(file_content, file_name)
            elif file_extension in ['.kml', '.geojson']:
                return self._process_gis_file(file_content, file_extension)
            else:
                st.warning(f"âš ï¸ æœªå¯¾å¿œã®æ‹¡å¼µå­: {file_extension}")
                return False
                
        except Exception as e:
            st.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return False

    def _process_zip_file(self, zip_content: bytes, zip_name: str) -> bool:
        """ZIPãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ï¼ˆå®Œå…¨ä¿®æ­£ç‰ˆï¼‰"""
        try:
            st.write(f"ğŸ“¦ ZIPå‡¦ç†é–‹å§‹: {zip_name}")
            
            with tempfile.TemporaryDirectory() as temp_dir:
                # ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£å‡
                with zipfile.ZipFile(io.BytesIO(zip_content)) as zip_file:
                    zip_file.extractall(temp_dir)
                    file_list = zip_file.namelist()
                    
                    st.write(f"ğŸ“¦ ZIPå†…ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ ({len(file_list)}å€‹):")
                    for file in file_list[:10]:  # æœ€åˆã®10å€‹ã¾ã§è¡¨ç¤º
                        st.write(f"  ğŸ“„ {file}")
                    if len(file_list) > 10:
                        st.write(f"  ... ä»–{len(file_list)-10}å€‹")
                
                # å®Ÿéš›ã«è§£å‡ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèª
                extracted_files = []
                for root, dirs, files in os.walk(temp_dir):
                    for file in files:
                        file_path = os.path.join(root, file)
                        rel_path = os.path.relpath(file_path, temp_dir)
                        extracted_files.append({
                            'name': file,
                            'path': file_path,
                            'relative_path': rel_path,
                            'extension': '.' + file.lower().split('.')[-1] if '.' in file else ''
                        })
                
                st.write(f"ğŸ—‚ï¸ è§£å‡ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ« ({len(extracted_files)}å€‹):")
                for file_info in extracted_files[:10]:
                    st.write(f"  ğŸ“„ {file_info['name']} ({file_info['extension']})")
                if len(extracted_files) > 10:
                    st.write(f"  ... ä»–{len(extracted_files)-10}å€‹")
                
                # å‡¦ç†å¯èƒ½ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é †æ¬¡ãƒã‚§ãƒƒã‚¯
                success = False
                
                # 1. Shapefileã‚’æœ€å„ªå…ˆã§å‡¦ç†
                success = self._try_process_shapefiles(extracted_files, temp_dir)
                if success:
                    return True
                
                # 2. CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†
                success = self._try_process_csv_files(extracted_files, temp_dir)
                if success:
                    return True
                
                # 3. Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†
                success = self._try_process_excel_files(extracted_files, temp_dir)
                if success:
                    return True
                
                # 4. ãã®ä»–ã®GISãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†
                success = self._try_process_other_gis_files(extracted_files, temp_dir)
                if success:
                    return True
                
                # 5. å…¨ã¦å¤±æ•—ã—ãŸå ´åˆã¯ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã§ç¶™ç¶š
                st.warning("âš ï¸ å‡¦ç†å¯èƒ½ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ãŒã€ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã§ç¶™ç¶šã—ã¾ã™")
                return self._create_dummy_area_data(zip_name)
                
        except zipfile.BadZipFile:
            st.error("âŒ ç„¡åŠ¹ãªZIPãƒ•ã‚¡ã‚¤ãƒ«ã§ã™")
            return False
        except Exception as e:
            st.error(f"âŒ ZIPå‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return False

    def _try_process_shapefiles(self, extracted_files: List[Dict], temp_dir: str) -> bool:
        """Shapefileã®å‡¦ç†ã‚’è©¦è¡Œ"""
        try:
            # Shapefileã‚’æ¢ã™
            shp_files = [f for f in extracted_files if f['extension'] == '.shp']
            
            if not shp_files:
                st.info("â„¹ï¸ ShapefileãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return False
            
            st.write(f"ğŸ—ºï¸ Shapefileç™ºè¦‹: {len(shp_files)}å€‹")
            for shp_file in shp_files:
                st.write(f"  ğŸ“ {shp_file['name']}")
            
            # æœ€åˆã®Shapefileã‚’å‡¦ç†
            shp_file = shp_files[0]
            shp_path = shp_file['path']
            
            st.write(f"ğŸ“¥ Shapefileèª­ã¿è¾¼ã¿: {shp_file['name']}")
            
            # GeoPandasã§èª­ã¿è¾¼ã¿
            gdf = gpd.read_file(shp_path)
            
            st.write(f"ğŸ“Š Shapefileæƒ…å ±:")
            st.write(f"  - ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(gdf):,}")
            st.write(f"  - åˆ—æ•°: {len(gdf.columns)}")
            st.write(f"  - åº§æ¨™ç³»: {gdf.crs}")
            
            # åˆ—åã‚’è¡¨ç¤º
            st.write(f"  - åˆ—å: {', '.join(gdf.columns[:10])}")
            if len(gdf.columns) > 10:
                st.write(f"    ... ä»–{len(gdf.columns)-10}å€‹")
            
            # å¤§å­—ãƒ»ä¸ç›®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
            area_data = self._extract_area_data_from_gdf(gdf)
            if area_data:
                st.session_state.area_data = area_data
                st.success(f"âœ… å¤§å­—ãƒ»ä¸ç›®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º: {len(area_data)}å€‹")
                return True
            else:
                st.info("â„¹ï¸ å¤§å­—ãƒ»ä¸ç›®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ãŒã€Shapefileèª­ã¿è¾¼ã¿ã¯æˆåŠŸ")
                # åŸºæœ¬çš„ãªã‚¨ãƒªã‚¢ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
                return self._create_basic_area_data_from_gdf(gdf)
                
        except Exception as e:
            st.warning(f"âš ï¸ Shapefileå‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return False

    def _try_process_csv_files(self, extracted_files: List[Dict], temp_dir: str) -> bool:
        """CSVãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ã‚’è©¦è¡Œ"""
        try:
            csv_files = [f for f in extracted_files if f['extension'] == '.csv']
            
            if not csv_files:
                return False
            
            st.write(f"ğŸ“„ CSVãƒ•ã‚¡ã‚¤ãƒ«ç™ºè¦‹: {len(csv_files)}å€‹")
            
            # æœ€åˆã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†
            csv_file = csv_files[0]
            
            # è¤‡æ•°ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’è©¦è¡Œ
            encodings = ['utf-8', 'shift-jis', 'cp932', 'utf-8-sig']
            df = None
            
            for encoding in encodings:
                try:
                    df = pd.read_csv(csv_file['path'], encoding=encoding)
                    st.success(f"âœ… CSVèª­ã¿è¾¼ã¿æˆåŠŸ (ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°: {encoding})")
                    break
                except:
                    continue
            
            if df is None:
                st.error("âŒ CSVèª­ã¿è¾¼ã¿å¤±æ•—ï¼ˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å•é¡Œï¼‰")
                return False
            
            st.write(f"ğŸ“Š CSVæƒ…å ±:")
            st.write(f"  - è¡Œæ•°: {len(df):,}")
            st.write(f"  - åˆ—æ•°: {len(df.columns)}")
            st.write(f"  - åˆ—å: {', '.join(df.columns[:5])}")
            
            # ã‚¨ãƒªã‚¢ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
            area_data = self._extract_area_data_from_df(df)
            if area_data:
                st.session_state.area_data = area_data
                st.success(f"âœ… ã‚¨ãƒªã‚¢ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º: {len(area_data)}å€‹")
                return True
            
            return False
            
        except Exception as e:
            st.warning(f"âš ï¸ CSVå‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return False

    def _try_process_excel_files(self, extracted_files: List[Dict], temp_dir: str) -> bool:
        """Excelãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ã‚’è©¦è¡Œ"""
        try:
            excel_files = [f for f in extracted_files if f['extension'] in ['.xlsx', '.xls']]
            
            if not excel_files:
                return False
            
            st.write(f"ğŸ“Š Excelãƒ•ã‚¡ã‚¤ãƒ«ç™ºè¦‹: {len(excel_files)}å€‹")
            
            # æœ€åˆã®Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†
            excel_file = excel_files[0]
            
            df = pd.read_excel(excel_file['path'])
            
            st.write(f"ğŸ“Š Excelæƒ…å ±:")
            st.write(f"  - è¡Œæ•°: {len(df):,}")
            st.write(f"  - åˆ—æ•°: {len(df.columns)}")
            st.write(f"  - åˆ—å: {', '.join(df.columns[:5])}")
            
            # ã‚¨ãƒªã‚¢ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
            area_data = self._extract_area_data_from_df(df)
            if area_data:
                st.session_state.area_data = area_data
                st.success(f"âœ… ã‚¨ãƒªã‚¢ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º: {len(area_data)}å€‹")
                return True
            
            return False
            
        except Exception as e:
            st.warning(f"âš ï¸ Excelå‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return False

    def _try_process_other_gis_files(self, extracted_files: List[Dict], temp_dir: str) -> bool:
        """ãã®ä»–ã®GISãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ã‚’è©¦è¡Œ"""
        try:
            gis_files = [f for f in extracted_files if f['extension'] in ['.kml', '.geojson', '.gpx']]
            
            if not gis_files:
                return False
            
            st.write(f"ğŸ—ºï¸ GISãƒ•ã‚¡ã‚¤ãƒ«ç™ºè¦‹: {len(gis_files)}å€‹")
            
            # æœ€åˆã®GISãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†
            gis_file = gis_files[0]
            
            gdf = gpd.read_file(gis_file['path'])
            
            st.write(f"ğŸ“Š GISãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±:")
            st.write(f"  - ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(gdf):,}")
            st.write(f"  - åˆ—æ•°: {len(gdf.columns)}")
            st.write(f"  - åº§æ¨™ç³»: {gdf.crs}")
            
            # ã‚¨ãƒªã‚¢ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
            area_data = self._extract_area_data_from_gdf(gdf)
            if area_data:
                st.session_state.area_data = area_data
                st.success(f"âœ… ã‚¨ãƒªã‚¢ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º: {len(area_data)}å€‹")
                return True
            
            return False
            
        except Exception as e:
            st.warning(f"âš ï¸ GISãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return False

    def _extract_area_data_from_gdf(self, gdf: gpd.GeoDataFrame) -> Optional[Dict[str, List[str]]]:
        """GeoPandasãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰å¤§å­—ãƒ»ä¸ç›®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º"""
        try:
            area_data = {}
            
            # å¤§å­—ååˆ—ã‚’æ¢ã™ï¼ˆè¤‡æ•°ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
            oaza_columns = []
            for col in gdf.columns:
                col_lower = col.lower()
                if any(keyword in col_lower for keyword in ['å¤§å­—', 'oaza', 'åœ°åŒº', 'ç”ºå']):
                    oaza_columns.append(col)
            
            # ä¸ç›®ååˆ—ã‚’æ¢ã™
            chome_columns = []
            for col in gdf.columns:
                col_lower = col.lower()
                if any(keyword in col_lower for keyword in ['ä¸ç›®', 'chome', 'ç•ªåœ°']):
                    chome_columns.append(col)
            
            if not oaza_columns:
                st.info("â„¹ï¸ å¤§å­—åã«è©²å½“ã™ã‚‹åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return None
            
            oaza_col = oaza_columns[0]
            st.write(f"ğŸï¸ å¤§å­—ååˆ—ã¨ã—ã¦ä½¿ç”¨: {oaza_col}")
            
            # å¤§å­—åã”ã¨ã«ä¸ç›®ã‚’é›†è¨ˆ
            for oaza in gdf[oaza_col].dropna().unique():
                oaza_str = str(oaza).strip()
                if oaza_str and oaza_str != 'nan':
                    area_data[oaza_str] = []
                    
                    if chome_columns:
                        chome_col = chome_columns[0]
                        st.write(f"ğŸ˜ï¸ ä¸ç›®ååˆ—ã¨ã—ã¦ä½¿ç”¨: {chome_col}")
                        
                        # è©²å½“ã™ã‚‹å¤§å­—ã®ä¸ç›®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                        oaza_data = gdf[gdf[oaza_col] == oaza]
                        chome_list = oaza_data[chome_col].dropna().unique()
                        
                        chome_str_list = []
                        for chome in chome_list:
                            chome_str = str(chome).strip()
                            if chome_str and chome_str != 'nan':
                                chome_str_list.append(chome_str)
                        
                        area_data[oaza_str] = sorted(chome_str_list) if chome_str_list else ["ä¸ç›®ãƒ‡ãƒ¼ã‚¿ãªã—"]
                    else:
                        area_data[oaza_str] = ["ä¸ç›®ãƒ‡ãƒ¼ã‚¿ãªã—"]
            
            # ç©ºã®ã‚¨ãƒªã‚¢ãƒ‡ãƒ¼ã‚¿ã‚’é™¤å¤–
            area_data = {k: v for k, v in area_data.items() if k and v}
            
            return area_data if area_data else None
            
        except Exception as e:
            st.error(f"âŒ GDFå¤§å­—ãƒ»ä¸ç›®ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None

    def _extract_area_data_from_df(self, df: pd.DataFrame) -> Optional[Dict[str, List[str]]]:
        """Pandasãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰å¤§å­—ãƒ»ä¸ç›®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º"""
        try:
            area_data = {}
            
            # å¤§å­—ååˆ—ã‚’æ¢ã™
            oaza_columns = []
            for col in df.columns:
                col_str = str(col).lower()
                if any(keyword in col_str for keyword in ['å¤§å­—', 'oaza', 'åœ°åŒº', 'ç”ºå']):
                    oaza_columns.append(col)
            
            if not oaza_columns:
                st.info("â„¹ï¸ å¤§å­—åã«è©²å½“ã™ã‚‹åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return None
            
            oaza_col = oaza_columns[0]
            st.write(f"ğŸï¸ å¤§å­—ååˆ—ã¨ã—ã¦ä½¿ç”¨: {oaza_col}")
            
            # å¤§å­—åä¸€è¦§ã‚’å–å¾—
            for oaza in df[oaza_col].dropna().unique():
                oaza_str = str(oaza).strip()
                if oaza_str and oaza_str != 'nan':
                    area_data[oaza_str] = ["ä¸ç›®ãƒ‡ãƒ¼ã‚¿ãªã—"]
            
            return area_data if area_data else None
            
        except Exception as e:
            st.error(f"âŒ DFå¤§å­—ãƒ»ä¸ç›®ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None

    def _create_basic_area_data_from_gdf(self, gdf: gpd.GeoDataFrame) -> bool:
        """GeoDataFrameã‹ã‚‰åŸºæœ¬çš„ãªã‚¨ãƒªã‚¢ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ"""
        try:
            # åœ°åŸŸã«é–¢é€£ã™ã‚‹åˆ—ã‚’æ¢ã™
            area_columns = []
            for col in gdf.columns:
                col_lower = str(col).lower()
                if any(keyword in col_lower for keyword in ['å', 'name', 'åœ°', 'åŒº', 'ç”º', 'æ‘']):
                    area_columns.append(col)
            
            if area_columns:
                area_col = area_columns[0]
                unique_areas = gdf[area_col].dropna().unique()
                
                area_data = {}
                for area in unique_areas[:20]:  # æœ€å¤§20å€‹ã¾ã§
                    area_str = str(area).strip()
                    if area_str and area_str != 'nan':
                        area_data[area_str] = ["ãƒ‡ãƒ¼ã‚¿ãªã—"]
                
                if area_data:
                    st.session_state.area_data = area_data
                    st.success(f"âœ… åŸºæœ¬ã‚¨ãƒªã‚¢ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ: {len(area_data)}å€‹")
                    return True
            
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿
            return self._create_dummy_area_data("Shapefile")
            
        except Exception as e:
            st.warning(f"âš ï¸ åŸºæœ¬ã‚¨ãƒªã‚¢ãƒ‡ãƒ¼ã‚¿ä½œæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
            return self._create_dummy_area_data("Shapefile")

    def _create_dummy_area_data(self, source_name: str) -> bool:
        """ãƒ€ãƒŸãƒ¼ã®å¤§å­—ãƒ»ä¸ç›®ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ"""
        try:
            # æ²–ç¸„çœŒã®ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
            dummy_area_data = {
                "é‚£è¦‡": ["1ä¸ç›®", "2ä¸ç›®", "3ä¸ç›®"],
                "é¦–é‡Œ": ["1ä¸ç›®", "2ä¸ç›®", "3ä¸ç›®", "4ä¸ç›®", "5ä¸ç›®"],
                "çœŸå˜‰æ¯”": ["1ä¸ç›®", "2ä¸ç›®", "3ä¸ç›®"],
                "æ³Š": ["1ä¸ç›®", "2ä¸ç›®", "3ä¸ç›®"],
                "ä¹…èŒ‚åœ°": ["1ä¸ç›®", "2ä¸ç›®", "3ä¸ç›®"],
                "ç‰§å¿—": ["1ä¸ç›®", "2ä¸ç›®", "3ä¸ç›®"],
                "å®‰é‡Œ": ["1ä¸ç›®", "2ä¸ç›®"],
                "ä¸ŠåŸ": ["1ä¸ç›®", "2ä¸ç›®", "3ä¸ç›®"],
                "å®®é‡Œ": ["1ä¸ç›®", "2ä¸ç›®"],
                "æ™®å¤©é–“": ["1ä¸ç›®", "2ä¸ç›®", "3ä¸ç›®", "4ä¸ç›®"]
            }
            
            st.session_state.area_data = dummy_area_data
            st.warning(f"âš ï¸ {source_name}ã‹ã‚‰é©åˆ‡ãªãƒ‡ãƒ¼ã‚¿ãŒæŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ")
            st.info(f"ğŸ’¡ ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã§ç¶™ç¶šã—ã¾ã™ï¼ˆ{len(dummy_area_data)}å€‹ã®å¤§å­—ï¼‰")
            
            return True
            
        except Exception as e:
            st.error(f"âŒ ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ä½œæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
            return False

    def _process_data_file(self, file_content: bytes, file_extension: str) -> bool:
        """ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆCSV/Excelï¼‰ã®å‡¦ç†"""
        try:
            if file_extension == '.csv':
                # è¤‡æ•°ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’è©¦è¡Œ
                encodings = ['utf-8', 'shift-jis', 'cp932', 'utf-8-sig']
                df = None
                
                for encoding in encodings:
                    try:
                        df = pd.read_csv(io.BytesIO(file_content), encoding=encoding)
                        break
                    except:
                        continue
                
                if df is None:
                    st.error("âŒ CSVèª­ã¿è¾¼ã¿å¤±æ•—")
                    return False
                    
            else:  # Excel
                df = pd.read_excel(io.BytesIO(file_content))
            
            st.write(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±:")
            st.write(f"  - è¡Œæ•°: {len(df):,}")
            st.write(f"  - åˆ—æ•°: {len(df.columns)}")
            
            # ã‚¨ãƒªã‚¢ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
            area_data = self._extract_area_data_from_df(df)
            if area_data:
                st.session_state.area_data = area_data
                st.success(f"âœ… ã‚¨ãƒªã‚¢ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º: {len(area_data)}å€‹")
                return True
            
            return self._create_dummy_area_data("ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«")
            
        except Exception as e:
            st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return False

    def _process_shapefile(self, file_content: bytes, file_name: str) -> bool:
        """å˜ä½“Shapefileã®å‡¦ç†"""
        try:
            with tempfile.NamedTemporaryFile(suffix='.shp', delete=False) as temp_file:
                temp_file.write(file_content)
                temp_file.flush()
                
                gdf = gpd.read_file(temp_file.name)
                
                area_data = self._extract_area_data_from_gdf(gdf)
                if area_data:
                    st.session_state.area_data = area_data
                    st.success(f"âœ… Shapefileå‡¦ç†å®Œäº†: {len(area_data)}å€‹")
                    return True
                
                return self._create_dummy_area_data("Shapefile")
                
        except Exception as e:
            st.error(f"âŒ Shapefileå‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return False
        finally:
            try:
                os.unlink(temp_file.name)
            except:
                pass

    def _process_gis_file(self, file_content: bytes, file_extension: str) -> bool:
        """GISãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆKML/GeoJSONï¼‰ã®å‡¦ç†"""
        try:
            with tempfile.NamedTemporaryFile(suffix=file_extension, delete=False) as temp_file:
                temp_file.write(file_content)
                temp_file.flush()
                
                gdf = gpd.read_file(temp_file.name)
                
                area_data = self._extract_area_data_from_gdf(gdf)
                if area_data:
                    st.session_state.area_data = area_data
                    st.success(f"âœ… GISãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†å®Œäº†: {len(area_data)}å€‹")
                    return True
                
                return self._create_dummy_area_data("GISãƒ•ã‚¡ã‚¤ãƒ«")
                
        except Exception as e:
            st.error(f"âŒ GISãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return False
        finally:
            try:
                os.unlink(temp_file.name)
            except:
                pass