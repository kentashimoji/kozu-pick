#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
src/utils.py - ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°ã¨ã‚¯ãƒ©ã‚¹

ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å…¨ä½“ã§ä½¿ç”¨ã•ã‚Œã‚‹å…±é€šæ©Ÿèƒ½ã‚’æä¾›
- ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ç®¡ç†
- ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ˜ãƒ«ãƒ‘ãƒ¼
- ãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œ
- æ–‡å­—åˆ—å‡¦ç†
- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
"""

import streamlit as st
import pandas as pd
import re
import os
from datetime import datetime
from typing import Dict, List, Optional, Any, Union
import zipfile
import tempfile
import shutil

class SessionStateManager:
    """Streamlitã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®ç®¡ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.default_state = {
            'prefecture_data': {},
            'prefecture_codes': {},
            'city_codes': {},
            'data_loaded': False,
            'current_url': "",
            'selected_prefecture': "",
            'selected_city': "",
            'selected_file_path': "",
            'area_data': {},
            'selected_oaza': "",
            'selected_chome': "",
            'folder_path': ""
        }
    
    def init_session_state(self):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’åˆæœŸåŒ–"""
        for key, default_value in self.default_state.items():
            if key not in st.session_state:
                st.session_state[key] = default_value
    
    def reset_session_state(self):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ"""
        for key, default_value in self.default_state.items():
            st.session_state[key] = default_value
    
    def clear_selection_data(self):
        """é¸æŠãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚¯ãƒªã‚¢"""
        selection_keys = [
            'selected_prefecture', 'selected_city', 
            'selected_oaza', 'selected_chome'
        ]
        for key in selection_keys:
            st.session_state[key] = ""
    
    def clear_area_data(self):
        """å¤§å­—ãƒ»ä¸ç›®ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢"""
        area_keys = ['area_data', 'selected_oaza', 'selected_chome', 'selected_file_path']
        for key in area_keys:
            if key in ['area_data']:
                st.session_state[key] = {}
            else:
                st.session_state[key] = ""
    
    def get_state_info(self) -> Dict[str, Any]:
        """ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹æƒ…å ±ã‚’å–å¾—"""
        return {
            'data_loaded': st.session_state.get('data_loaded', False),
            'has_prefecture_data': bool(st.session_state.get('prefecture_data')),
            'has_area_data': bool(st.session_state.get('area_data')),
            'selected_prefecture': st.session_state.get('selected_prefecture', ''),
            'selected_city': st.session_state.get('selected_city', ''),
            'current_url': st.session_state.get('current_url', ''),
            'total_prefectures': len(st.session_state.get('prefecture_data', {})),
            'total_cities': sum(len(cities) for cities in st.session_state.get('prefecture_data', {}).values())
        }

class DataProcessor:
    """ãƒ‡ãƒ¼ã‚¿å‡¦ç†ç”¨ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼ã‚¯ãƒ©ã‚¹"""
    
    @staticmethod
    def extract_area_from_dataframe(df: pd.DataFrame) -> Dict[str, List[str]]:
        """ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰å¤§å­—ãƒ»ä¸ç›®ã‚’æŠ½å‡ºï¼ˆãƒ‡ãƒãƒƒã‚°å¼·åŒ–ç‰ˆï¼‰"""
        import streamlit as st
        
        st.write(f"ğŸ” å¤§å­—ãƒ»ä¸ç›®æŠ½å‡ºé–‹å§‹")
        st.write(f"  - ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {df.shape}")
        st.write(f"  - åˆ—å: {list(df.columns)}")
        
        # å¯èƒ½æ€§ã®ã‚ã‚‹åˆ—åãƒ‘ã‚¿ãƒ¼ãƒ³
        oaza_patterns = ['å¤§å­—', 'ãŠãŠã‚ã–', 'ã‚ªã‚ªã‚¢ã‚¶', 'OAZA', 'oaza', 'å­—', 'ç”ºå', 'TOWN', 'town', 'å¤§å­—å', 'å°å­—', 'å°å­—å']
        chome_patterns = ['ä¸ç›®', 'ã¡ã‚‡ã†ã‚', 'ãƒãƒ§ã‚¦ãƒ¡', 'CHOME', 'chome', 'ä¸', 'ç•ªåœ°', 'ä¸ç›®å']
        address_patterns = ['ä½æ‰€', 'address', 'ADDRESS', 'æ‰€åœ¨åœ°', 'åœ°å', 'name', 'NAME', 'åœ°åŒºå', 'ç”ºå­—å']
        
        area_data = {}
        
        # åˆ—åã‚’å–å¾—
        columns = [str(col).lower() for col in df.columns]
        
        # å¤§å­—ãƒ»ä¸ç›®ã®å°‚ç”¨åˆ—ã‚’æ¤œç´¢
        oaza_col = None
        chome_col = None
        address_col = None
        
        st.write(f"ğŸ” åˆ—ååˆ†æ:")
        
        for col in df.columns:
            col_lower = str(col).lower()
            
            # å¤§å­—åˆ—ã®æ¤œç´¢
            if not oaza_col:
                for pattern in oaza_patterns:
                    if pattern.lower() in col_lower:
                        oaza_col = col
                        st.write(f"  âœ… å¤§å­—åˆ—ç™ºè¦‹: {col} (ãƒ‘ã‚¿ãƒ¼ãƒ³: {pattern})")
                        break
            
            # ä¸ç›®åˆ—ã®æ¤œç´¢
            if not chome_col:
                for pattern in chome_patterns:
                    if pattern.lower() in col_lower:
                        chome_col = col
                        st.write(f"  âœ… ä¸ç›®åˆ—ç™ºè¦‹: {col} (ãƒ‘ã‚¿ãƒ¼ãƒ³: {pattern})")
                        break
            
            # ä½æ‰€åˆ—ã®æ¤œç´¢
            if not address_col:
                for pattern in address_patterns:
                    if pattern.lower() in col_lower:
                        address_col = col
                        st.write(f"  âœ… ä½æ‰€åˆ—ç™ºè¦‹: {col} (ãƒ‘ã‚¿ãƒ¼ãƒ³: {pattern})")
                        break
        
        st.write(f"ğŸ” æ¤œå‡ºçµæœ:")
        st.write(f"  - å¤§å­—åˆ—: {oaza_col}")
        st.write(f"  - ä¸ç›®åˆ—: {chome_col}")
        st.write(f"  - ä½æ‰€åˆ—: {address_col}")
        
        # ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
        if oaza_col:
            st.write(f"ğŸ“Š å¤§å­—å°‚ç”¨åˆ—ã‹ã‚‰æŠ½å‡ºä¸­...")
            # å¤§å­—ã®å°‚ç”¨åˆ—ãŒã‚ã‚‹å ´åˆ
            for idx, row in df.iterrows():
                oaza = str(row[oaza_col]) if pd.notna(row[oaza_col]) else ""
                oaza = oaza.strip()
                
                if oaza and oaza != 'nan' and len(oaza) > 0:
                    if oaza not in area_data:
                        area_data[oaza] = set()
                    
                    # ä¸ç›®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆ
                    if chome_col and pd.notna(row[chome_col]):
                        chome = str(row[chome_col]).strip()
                        if chome and chome != 'nan' and len(chome) > 0:
                            area_data[oaza].add(chome)
                
                # é€²æ—è¡¨ç¤ºï¼ˆæœ€åˆã®10è¡Œã®ã¿ï¼‰
                if idx < 10:
                    st.write(f"    è¡Œ{idx+1}: å¤§å­—='{oaza}', ä¸ç›®='{str(row[chome_col]) if chome_col and pd.notna(row[chome_col]) else 'ãªã—'}'")
        
        elif address_col:
            st.write(f"ğŸ“Š ä½æ‰€åˆ—ã‹ã‚‰æ­£è¦è¡¨ç¾ã§æŠ½å‡ºä¸­...")
            # ä½æ‰€åˆ—ã‹ã‚‰æŠ½å‡º
            import re
            
            for idx, row in df.iterrows():
                address = str(row[address_col]) if pd.notna(row[address_col]) else ""
                
                # æ­£è¦è¡¨ç¾ã§å¤§å­—ãƒ»ä¸ç›®ã‚’æŠ½å‡º
                oaza_matches = re.findall(r'å¤§å­—(.+?)(?:[0-9]|ä¸ç›®|ç•ªåœ°|$)', address)
                chome_matches = re.findall(r'([0-9]+ä¸ç›®)', address)
                
                for oaza_match in oaza_matches:
                    oaza = oaza_match.strip()
                    if oaza:
                        if oaza not in area_data:
                            area_data[oaza] = set()
                        
                        for chome in chome_matches:
                            area_data[oaza].add(chome)
                
                # é€²æ—è¡¨ç¤ºï¼ˆæœ€åˆã®10è¡Œã®ã¿ï¼‰
                if idx < 10:
                    st.write(f"    è¡Œ{idx+1}: ä½æ‰€='{address[:50]}...', å¤§å­—={oaza_matches}, ä¸ç›®={chome_matches}")
        
        else:
            st.write(f"ğŸ“Š å…¨åˆ—ã‹ã‚‰ä½æ‰€æƒ…å ±ã‚’æ¤œç´¢ä¸­...")
            # å…¨ã¦ã®åˆ—ã‹ã‚‰ä½æ‰€ã‚‰ã—ã„æƒ…å ±ã‚’æŠ½å‡º
            import re
            
            for col in df.columns:
                if df[col].dtype == 'object':  # æ–‡å­—åˆ—å‹ã®åˆ—ã®ã¿
                    st.write(f"  - æ¤œç´¢ä¸­ã®åˆ—: {col}")
                    found_count = 0
                    
                    for idx, row in df.iterrows():
                        value = str(row[col]) if pd.notna(row[col]) else ""
                        
                        # å¤§å­—ãƒ»ä¸ç›®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œç´¢
                        if 'å¤§å­—' in value or 'ä¸ç›®' in value or 'å°å­—' in value:
                            oaza_matches = re.findall(r'(?:å¤§å­—|å°å­—)(.+?)(?:[0-9]|ä¸ç›®|ç•ªåœ°|$)', value)
                            chome_matches = re.findall(r'([0-9]+ä¸ç›®)', value)
                            
                            for oaza_match in oaza_matches:
                                oaza = oaza_match.strip()
                                if oaza and len(oaza) > 0:
                                    if oaza not in area_data:
                                        area_data[oaza] = set()
                                    
                                    for chome in chome_matches:
                                        area_data[oaza].add(chome)
                                    
                                    found_count += 1
                    
                    if found_count > 0:
                        st.write(f"    âœ… {found_count}ä»¶ã®ä½æ‰€æƒ…å ±ã‚’ç™ºè¦‹")
        
        # Setã‚’Listã«å¤‰æ›ã—ã¦ã‚½ãƒ¼ãƒˆ
        for oaza in area_data:
            area_data[oaza] = sorted(list(area_data[oaza]))
        
        st.write(f"âœ… æŠ½å‡ºå®Œäº†: {len(area_data)}å€‹ã®å¤§å­—")
        
        if area_data:
            # æŠ½å‡ºçµæœã®ã‚µãƒ³ãƒ—ãƒ«ã‚’è¡¨ç¤º
            sample_items = list(area_data.items())[:3]
            for oaza, chome_list in sample_items:
                st.write(f"  - {oaza}: {len(chome_list)}å€‹ã®ä¸ç›® {chome_list[:3] if chome_list else '(ãªã—)'}")
        
        return area_data
    
    @staticmethod
    def sort_prefectures_with_okinawa_first(prefecture_data: Dict, prefecture_codes: Dict) -> Dict:
        """æ²–ç¸„çœŒã‚’æœ€åˆã«ã—ã¦éƒ½é“åºœçœŒã‚’ã‚½ãƒ¼ãƒˆ"""
        sorted_prefs = []
        other_prefs = []
        
        for pref in prefecture_data.keys():
            if pref == 'æ²–ç¸„çœŒ':
                sorted_prefs.insert(0, pref)  # æœ€åˆã«æŒ¿å…¥
            else:
                other_prefs.append(pref)
        
        # æ²–ç¸„çœŒä»¥å¤–ã‚’å›£ä½“ã‚³ãƒ¼ãƒ‰é †ã«ã‚½ãƒ¼ãƒˆ
        other_prefs.sort(key=lambda x: prefecture_codes.get(x, '99'))
        
        all_prefs = sorted_prefs + other_prefs
        
        # ã‚½ãƒ¼ãƒˆæ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã§è¾æ›¸ã‚’å†æ§‹ç¯‰
        sorted_prefecture_data = {}
        for prefecture in all_prefs:
            sorted_prefecture_data[prefecture] = prefecture_data[prefecture]
        
        return sorted_prefecture_data
    
    @staticmethod
    def sort_cities_by_code(cities_dict: Dict) -> Dict:
        """å¸‚åŒºç”ºæ‘ã‚’å›£ä½“ã‚³ãƒ¼ãƒ‰é †ã«ã‚½ãƒ¼ãƒˆ"""
        sorted_cities = sorted(cities_dict.keys(), 
                             key=lambda x: cities_dict[x]['full_code'])
        
        # ã‚½ãƒ¼ãƒˆæ¸ˆã¿ã®å¸‚åŒºç”ºæ‘è¾æ›¸ã‚’ä½œæˆ
        sorted_cities_dict = {}
        for city in sorted_cities:
            sorted_cities_dict[city] = cities_dict[city]
        
        return sorted_cities_dict
        
    def organize_prefecture_data(df):
        """éƒ½é“åºœçœŒãƒ‡ãƒ¼ã‚¿ã‚’æ•´ç†"""
        import streamlit as st
        import pandas as pd
        
        prefecture_data = {}
        prefecture_codes = {}
        city_codes = {}

        # åˆ—åæ¤œç´¢
        prefecture_cols = [col for col in df.columns if 'éƒ½é“åºœçœŒ' in col and 'æ¼¢å­—' in col]
        city_cols = [col for col in df.columns if 'å¸‚åŒºç”ºæ‘' in col and 'æ¼¢å­—' in col]
        code_col = 'å›£ä½“ã‚³ãƒ¼ãƒ‰'

        if not prefecture_cols or not city_cols:
            st.error(f"é©åˆ‡ãªåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚åˆ©ç”¨å¯èƒ½ãªåˆ—: {list(df.columns)}")
            return None, None, None

        prefecture_col = prefecture_cols[0]
        city_col = city_cols[0]

        for _, row in df.iterrows():
            prefecture = row.get(prefecture_col)
            city = row.get(city_col)
            code = row.get(code_col, '')

            if pd.notna(prefecture):
                if prefecture not in prefecture_data:
                    prefecture_data[prefecture] = {}
                    if pd.notna(code):
                        prefecture_codes[prefecture] = str(code)[:2]

                if pd.notna(city):
                    full_code = str(code) if pd.notna(code) else '999999'
                    prefecture_code = full_code[:2]
                    city_code = full_code[2:5] if len(full_code) >= 5 else '999'

                    prefecture_data[prefecture][city] = {
                        'full_code': full_code,
                        'city_code': city_code
                    }

                    city_codes[f"{prefecture}_{city}"] = {
                        'prefecture_code': prefecture_code,
                        'city_code': city_code,
                        'full_code': full_code
                    }

        # éƒ½é“åºœçœŒã‚’ã‚½ãƒ¼ãƒˆï¼ˆæ²–ç¸„çœŒã‚’æœ€åˆã«ï¼‰
        sorted_prefecture_data = DataProcessor.sort_prefectures_with_okinawa_first(
            prefecture_data, prefecture_codes
        )

        return sorted_prefecture_data, prefecture_codes, city_codes

class FileHandler:
    """ãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œç”¨ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼ã‚¯ãƒ©ã‚¹"""
    
    @staticmethod
    def extract_zip_safely(zip_path: str, extract_to: str) -> List[str]:
        """ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’å®‰å…¨ã«å±•é–‹"""
        try:
            extracted_files = []
            
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                # å®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯
                for member in zip_ref.namelist():
                    if os.path.isabs(member) or ".." in member:
                        continue  # å±é™ºãªãƒ‘ã‚¹ã‚’ã‚¹ã‚­ãƒƒãƒ—
                
                zip_ref.extractall(extract_to)
            
            # å±•é–‹ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
            for root, dirs, files in os.walk(extract_to):
                for file in files:
                    if file.lower().endswith(('.shp', '.kml', '.geojson', '.csv', '.xlsx')):
                        extracted_files.append(os.path.join(root, file))
            
            return extracted_files
            
        except Exception as e:
            raise Exception(f"ZIPå±•é–‹ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    @staticmethod
    def create_temp_directory() -> str:
        """ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ"""
        return tempfile.mkdtemp()
    
    @staticmethod
    def cleanup_temp_directory(temp_dir: str):
        """ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        try:
            if os.path.exists(temp_dir):
                shutil.rmtree(temp_dir)
        except Exception:
            pass  # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼ã¯ç„¡è¦–

class StringHelper:
    """æ–‡å­—åˆ—å‡¦ç†ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼ã‚¯ãƒ©ã‚¹"""
    
    @staticmethod
    def clean_string(text: str) -> str:
        """æ–‡å­—åˆ—ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        if not text or pd.isna(text):
            return ""
        return str(text).strip()
    
    @staticmethod
    def extract_code_from_filename(filename: str) -> Optional[str]:
        """ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰å›£ä½“ã‚³ãƒ¼ãƒ‰ã‚’æŠ½å‡º"""
        # 6æ¡ã®æ•°å­—ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œç´¢
        pattern = r'(\d{6})'
        match = re.search(pattern, filename)
        return match.group(1) if match else None
    
    @staticmethod
    def format_address(prefecture: str, city: str, oaza: str = "", chome: str = "") -> str:
        """å®Œå…¨ãªä½æ‰€ã‚’æ ¼å¼åŒ–"""
        parts = [prefecture, city]
        if oaza:
            parts.append(oaza)
        if chome:
            parts.append(chome)
        return "".join(parts)
    
    @staticmethod
    def truncate_text(text: str, max_length: int = 60) -> str:
        """ãƒ†ã‚­ã‚¹ãƒˆã‚’æŒ‡å®šé•·ã§åˆ‡ã‚Šè©°ã‚"""
        if len(text) <= max_length:
            return text
        return text[:max_length] + "..."

class ValidationHelper:
    """ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼ã‚¯ãƒ©ã‚¹"""
    
    @staticmethod
    def is_valid_github_url(url: str) -> bool:
        """GitHub URLãŒæœ‰åŠ¹ã‹ãƒã‚§ãƒƒã‚¯"""
        if not url:
            return False
        return "github.com" in url or "raw.githubusercontent.com" in url
    
    @staticmethod
    def is_valid_prefecture_code(code: str) -> bool:
        """éƒ½é“åºœçœŒã‚³ãƒ¼ãƒ‰ãŒæœ‰åŠ¹ã‹ãƒã‚§ãƒƒã‚¯"""
        if not code or len(code) != 2:
            return False
        try:
            code_int = int(code)
            return 1 <= code_int <= 47
        except ValueError:
            return False
    
    @staticmethod
    def is_valid_city_code(code: str) -> bool:
        """å¸‚åŒºç”ºæ‘ã‚³ãƒ¼ãƒ‰ãŒæœ‰åŠ¹ã‹ãƒã‚§ãƒƒã‚¯"""
        if not code or len(code) != 3:
            return False
        try:
            int(code)
            return True
        except ValueError:
            return False
    
    @staticmethod
    def validate_dataframe_columns(df: pd.DataFrame, required_patterns: List[str]) -> Dict[str, bool]:
        """ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®åˆ—ãŒè¦ä»¶ã‚’æº€ãŸã™ã‹ãƒã‚§ãƒƒã‚¯"""
        results = {}
        columns = [str(col).lower() for col in df.columns]
        
        for pattern in required_patterns:
            results[pattern] = any(pattern.lower() in col for col in columns)
        
        return results

class ErrorHandler:
    """ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ç”¨ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼ã‚¯ãƒ©ã‚¹"""
    
    @staticmethod
    def handle_import_error(module_name: str, error: Exception):
        """ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼ã‚’å‡¦ç†"""
        st.error(f"ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« '{module_name}' ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {error}")
        st.info("å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    
    @staticmethod
    def handle_file_error(file_path: str, error: Exception):
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒ©ãƒ¼ã‚’å‡¦ç†"""
        st.error(f"ãƒ•ã‚¡ã‚¤ãƒ« '{file_path}' ã®å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: {error}")
        st.info("ãƒ•ã‚¡ã‚¤ãƒ«ã®å½¢å¼ã‚„ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    
    @staticmethod
    def handle_network_error(url: str, error: Exception):
        """ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼ã‚’å‡¦ç†"""
        st.error(f"ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼: {error}")
        st.info(f"URL '{url}' ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã›ã‚“ã€‚ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

class ProgressTracker:
    """é€²æ—è¿½è·¡ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, total_steps: int):
        self.total_steps = total_steps
        self.current_step = 0
        self.progress_bar = st.progress(0)
        self.status_text = st.empty()
    
    def update(self, step: int, message: str):
        """é€²æ—ã‚’æ›´æ–°"""
        self.current_step = step
        progress = min(step / self.total_steps, 1.0)
        self.progress_bar.progress(progress)
        self.status_text.text(message)
    
    def complete(self, message: str = "å®Œäº†ã—ã¾ã—ãŸ"):
        """é€²æ—ã‚’å®Œäº†"""
        self.progress_bar.progress(1.0)
        self.status_text.text(f"âœ… {message}")
    
    def error(self, message: str):
        """ã‚¨ãƒ©ãƒ¼çŠ¶æ…‹ã«è¨­å®š"""
        self.status_text.text(f"âŒ {message}")

class ConfigHelper:
    """è¨­å®šç®¡ç†ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼ã‚¯ãƒ©ã‚¹"""
    
    @staticmethod
    def get_default_github_config() -> Dict[str, Any]:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®GitHubè¨­å®šã‚’å–å¾—"""
        return {
            "user_agent": "PrefectureCitySelector/33.0",
            "timeout": 30,
            "default_url": "https://raw.githubusercontent.com/USERNAME/REPOSITORY/main/000925835.xlsx"
        }
    
    @staticmethod
    def get_default_gis_config() -> Dict[str, Any]:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®GISè¨­å®šã‚’å–å¾—"""
        return {
            "supported_extensions": ['.zip', '.shp', '.shx', '.prj', '.dbf', '.cpg', '.kml'],
            "shapefile_required": ['.shp', '.shx', '.dbf']
        }
    
    @staticmethod
    def get_app_info() -> Dict[str, Any]:
        """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æƒ…å ±ã‚’å–å¾—"""
        return {
            "name": "éƒ½é“åºœçœŒãƒ»å¸‚åŒºç”ºæ‘é¸æŠãƒ„ãƒ¼ãƒ«",
            "version": "33.0",
            "author": "AI Assistant",
            "description": "GitHubé€£æºå¯¾å¿œã®éƒ½é“åºœçœŒãƒ»å¸‚åŒºç”ºæ‘é¸æŠãƒ„ãƒ¼ãƒ«",
            "last_updated": datetime.now().strftime('%Y-%m-%d')
        }

# ä¾¿åˆ©ãªé–¢æ•°ï¼ˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ¬ãƒ™ãƒ«ï¼‰
def format_file_size(size_bytes: int) -> str:
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’äººé–“ãŒèª­ã¿ã‚„ã™ã„å½¢å¼ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
    if size_bytes == 0:
        return "0 B"
    
    size_names = ["B", "KB", "MB", "GB"]
    i = 0
    while size_bytes >= 1024 and i < len(size_names) - 1:
        size_bytes /= 1024.0
        i += 1
    
    return f"{size_bytes:.1f} {size_names[i]}"

def safe_convert_to_int(value: Any, default: int = 0) -> int:
    """å®‰å…¨ã«æ•´æ•°ã«å¤‰æ›"""
    try:
        return int(value) if value is not None else default
    except (ValueError, TypeError):
        return default

def safe_convert_to_str(value: Any, default: str = "") -> str:
    """å®‰å…¨ã«æ–‡å­—åˆ—ã«å¤‰æ›"""
    try:
        return str(value) if value is not None else default
    except (ValueError, TypeError):
        return default

def generate_timestamp() -> str:
    """ç¾åœ¨æ™‚åˆ»ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ç”Ÿæˆ"""
    return datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')

def debug_session_state():
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ãƒ‡ãƒãƒƒã‚°è¡¨ç¤º"""
    if st.checkbox("ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ãƒ‡ãƒãƒƒã‚°è¡¨ç¤º"):
        st.json(dict(st.session_state))

def organize_prefecture_data(df):
        """éƒ½é“åºœçœŒãƒ‡ãƒ¼ã‚¿ã‚’æ•´ç†ï¼ˆdata_loaderã‹ã‚‰ç§»å‹•ï¼‰"""
        prefecture_data = {}
        prefecture_codes = {}
        city_codes = {}

        # åˆ—åæ¤œç´¢
        prefecture_cols = [col for col in df.columns if 'éƒ½é“åºœçœŒ' in col and 'æ¼¢å­—' in col]
        city_cols = [col for col in df.columns if 'å¸‚åŒºç”ºæ‘' in col and 'æ¼¢å­—' in col]
        code_col = 'å›£ä½“ã‚³ãƒ¼ãƒ‰'

        if not prefecture_cols or not city_cols:
            st.error(f"é©åˆ‡ãªåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚åˆ©ç”¨å¯èƒ½ãªåˆ—: {list(df.columns)}")
            return None, None, None

        prefecture_col = prefecture_cols[0]
        city_col = city_cols[0]

        for _, row in df.iterrows():
            prefecture = row.get(prefecture_col)
            city = row.get(city_col)
            code = row.get(code_col, '')

            if pd.notna(prefecture):
                if prefecture not in prefecture_data:
                    prefecture_data[prefecture] = {}
                    if pd.notna(code):
                        prefecture_codes[prefecture] = str(code)[:2]

                if pd.notna(city):
                    full_code = str(code) if pd.notna(code) else '999999'
                    prefecture_code = full_code[:2]
                    city_code = full_code[2:5] if len(full_code) >= 5 else '999'

                    prefecture_data[prefecture][city] = {
                        'full_code': full_code,
                        'city_code': city_code
                    }

                    city_codes[f"{prefecture}_{city}"] = {
                        'prefecture_code': prefecture_code,
                        'city_code': city_code,
                        'full_code': full_code
                    }

        # éƒ½é“åºœçœŒã‚’ã‚½ãƒ¼ãƒˆï¼ˆæ²–ç¸„çœŒã‚’æœ€åˆã«ï¼‰
        sorted_prefecture_data = DataProcessor.sort_prefectures_with_okinawa_first(
            prefecture_data, prefecture_codes
        )

        return sorted_prefecture_data, prefecture_codes, city_codes
