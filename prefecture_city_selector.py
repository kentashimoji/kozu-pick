#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
éƒ½é“åºœçœŒãƒ»å¸‚åŒºç”ºæ‘é¸æŠãƒ„ãƒ¼ãƒ« v33.0 (GISå¯¾å¿œç‰ˆ)
GitHub Excelãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä½œæˆ
GISãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆZIPã€Shapefileã€KMLï¼‰ã‹ã‚‰å¤§å­—ãƒ»ä¸ç›®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º

å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒª:
pip install streamlit pandas openpyxl requests geopandas fiona lxml

å®Ÿè¡Œæ–¹æ³•:
streamlit run prefecture_city_selector_streamlit.py
"""

import streamlit as st
import pandas as pd
import requests
from io import BytesIO
from datetime import datetime
import os
import glob
import zipfile
import tempfile
import re
import shutil

# GISé–¢é€£ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    import geopandas as gpd
    import fiona
    GEOPANDAS_AVAILABLE = True
except ImportError:
    GEOPANDAS_AVAILABLE = False
    st.warning("âš ï¸ GeoPandasãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚GISãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«ã¯GeoPandasã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒå¿…è¦ã§ã™ã€‚")

try:
    from lxml import etree
    XML_AVAILABLE = True
except ImportError:
    XML_AVAILABLE = False

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="éƒ½é“åºœçœŒãƒ»å¸‚åŒºç”ºæ‘é¸æŠãƒ„ãƒ¼ãƒ« v33.0",
    page_icon="ğŸ›ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

    class PrefectureCitySelectorGitHub:
    def __init__(self):
        self.init_session_state()
    
    def init_session_state(self):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’åˆæœŸåŒ–"""
        if 'prefecture_data' not in st.session_state:
            st.session_state.prefecture_data = {}
        if 'prefecture_codes' not in st.session_state:
            st.session_state.prefecture_codes = {}
        if 'city_codes' not in st.session_state:
            st.session_state.city_codes = {}
        if 'data_loaded' not in st.session_state:
            st.session_state.data_loaded = False
        if 'current_url' not in st.session_state:
            st.session_state.current_url = ""
        if 'selected_prefecture' not in st.session_state:
            st.session_state.selected_prefecture = ""
        if 'selected_city' not in st.session_state:
            st.session_state.selected_city = ""
        if 'selected_file_path' not in st.session_state:
            st.session_state.selected_file_path = ""
        if 'area_data' not in st.session_state:
            st.session_state.area_data = {}
        if 'selected_oaza' not in st.session_state:
            st.session_state.selected_oaza = ""
        if 'selected_chome' not in st.session_state:
            st.session_state.selected_chome = ""
        if 'folder_path' not in st.session_state:
            st.session_state.folder_path = ""
    
    def load_data_from_github(self, url):
        """GitHubã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        try:
            if not url:
                st.error("URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
                return False
                
            if "raw.githubusercontent.com" not in url:
                st.warning("GitHub Raw URLã§ã¯ãªã„ã‚ˆã†ã§ã™ã€‚æ­£ã—ã„URLã¯ 'raw.githubusercontent.com' ã‚’å«ã‚“ã§ã„ã¾ã™ã€‚")
            
            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã‚’è¡¨ç¤º
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            status_text.text("ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ã„ã¾ã™...")
            progress_bar.progress(25)
            
            headers = {'User-Agent': 'PrefectureCitySelector/39.0'}
            response = requests.get(url, headers=headers, timeout=30)
            response.raise_for_status()
            
            progress_bar.progress(50)
            status_text.text("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æã—ã¦ã„ã¾ã™...")
            
            # ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã‚’åˆ¤å®šã—ã¦èª­ã¿è¾¼ã¿
            if url.lower().endswith('.csv'):
                df = pd.read_csv(BytesIO(response.content), encoding='utf-8-sig')
            else:
                excel_data = BytesIO(response.content)
                df = pd.read_excel(excel_data)
            
            progress_bar.progress(75)
            status_text.text("ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã—ã¦ã„ã¾ã™...")
            
            # ãƒ‡ãƒ¼ã‚¿ã‚’æ•´ç†ï¼ˆå›£ä½“ã‚³ãƒ¼ãƒ‰ã¨å…±ã«ä¿å­˜ï¼‰
            prefecture_data = {}
            prefecture_codes = {}
            city_codes = {}
            
            prefecture_cols = [col for col in df.columns if 'éƒ½é“åºœçœŒ' in col and 'æ¼¢å­—' in col]
            city_cols = [col for col in df.columns if 'å¸‚åŒºç”ºæ‘' in col and 'æ¼¢å­—' in col]
            code_col = 'å›£ä½“ã‚³ãƒ¼ãƒ‰'
            
            if not prefecture_cols or not city_cols:
                st.error(f"é©åˆ‡ãªåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚åˆ©ç”¨å¯èƒ½ãªåˆ—: {list(df.columns)}")
                return False
            
            prefecture_col = prefecture_cols[0]
            city_col = city_cols[0]
            
            for _, row in df.iterrows():
                prefecture = row.get(prefecture_col)
                city = row.get(city_col)
                code = row.get(code_col, '')
                
                if pd.notna(prefecture):
                    if prefecture not in prefecture_data:
                        prefecture_data[prefecture] = {}
                        # éƒ½é“åºœçœŒã‚³ãƒ¼ãƒ‰ã‚’ä¿å­˜ï¼ˆæœ€åˆã®2æ¡ï¼‰
                        if pd.notna(code):
                            prefecture_codes[prefecture] = str(code)[:2]
                    
                    if pd.notna(city):
                        # å¸‚åŒºç”ºæ‘ã®è©³ç´°æƒ…å ±ã‚’ä¿å­˜
                        full_code = str(code) if pd.notna(code) else '999999'
                        prefecture_code = full_code[:2]  # 1-2æ¡ç›®
                        city_code = full_code[2:5] if len(full_code) >= 5 else '999'  # 3-5æ¡ç›®
                        
                        prefecture_data[prefecture][city] = {
                            'full_code': full_code,
                            'city_code': city_code
                        }
                        
                        # å…¨ä½“ã®ã‚³ãƒ¼ãƒ‰æƒ…å ±ã‚’ä¿å­˜
                        city_codes[f"{prefecture}_{city}"] = {
                            'prefecture_code': prefecture_code,
                            'city_code': city_code,
                            'full_code': full_code
                        }
            
            # éƒ½é“åºœçœŒã‚’å›£ä½“ã‚³ãƒ¼ãƒ‰é †ã«ã‚½ãƒ¼ãƒˆï¼ˆæ²–ç¸„çœŒã‚’æœ€åˆã«ï¼‰
            def sort_prefectures(prefectures_dict):
                # æ²–ç¸„çœŒã‚’ç‰¹åˆ¥æ‰±ã„
                sorted_prefs = []
                other_prefs = []
                
                for pref in prefectures_dict.keys():
                    if pref == 'æ²–ç¸„çœŒ':
                        sorted_prefs.insert(0, pref)  # æœ€åˆã«æŒ¿å…¥
                    else:
                        other_prefs.append(pref)
                
                # æ²–ç¸„çœŒä»¥å¤–ã‚’å›£ä½“ã‚³ãƒ¼ãƒ‰é †ã«ã‚½ãƒ¼ãƒˆ
                other_prefs.sort(key=lambda x: prefecture_codes.get(x, '99'))
                
                return sorted_prefs + other_prefs
            
            # å¸‚åŒºç”ºæ‘ã‚’å›£ä½“ã‚³ãƒ¼ãƒ‰é †ã«ã‚½ãƒ¼ãƒˆ
            for prefecture in prefecture_data:
                cities_with_info = prefecture_data[prefecture]
                sorted_cities = sorted(cities_with_info.keys(), 
                                     key=lambda x: cities_with_info[x]['full_code'])
                # ã‚½ãƒ¼ãƒˆæ¸ˆã¿ã®å¸‚åŒºç”ºæ‘è¾æ›¸ã‚’ä½œæˆ
                sorted_cities_dict = {}
                for city in sorted_cities:
                    sorted_cities_dict[city] = cities_with_info[city]
                prefecture_data[prefecture] = sorted_cities_dict
            
            # ã‚½ãƒ¼ãƒˆæ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã§è¾æ›¸ã‚’å†æ§‹ç¯‰
            sorted_prefecture_data = {}
            sorted_prefectures = sort_prefectures(prefecture_data)
            for prefecture in sorted_prefectures:
                sorted_prefecture_data[prefecture] = prefecture_data[prefecture]
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ã‚³ãƒ¼ãƒ‰æƒ…å ±ã‚‚ä¿å­˜
            st.session_state.prefecture_data = sorted_prefecture_data
            st.session_state.prefecture_codes = prefecture_codes
            st.session_state.city_codes = city_codes
            st.session_state.data_loaded = True
            st.session_state.current_url = url
            
            progress_bar.progress(100)
            status_text.text("âœ… ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
            
            # çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º
            total_prefectures = len(sorted_prefecture_data)
            total_cities = sum(len(cities) for cities in sorted_prefecture_data.values())
            
            st.success(f"ğŸ“Š èª­ã¿è¾¼ã¿å®Œäº†: {total_prefectures}éƒ½é“åºœçœŒ, {total_cities}å¸‚åŒºç”ºæ‘")
            
            return True
            
        except requests.RequestException as e:
            st.error(f"ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return False
        except Exception as e:
            st.error(f"ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
            return False
    
    def find_files_by_code_from_github(self, base_url, prefecture_code, city_code):
        """GitHubãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰å›£ä½“ã‚³ãƒ¼ãƒ‰ã«åŸºã¥ã„ã¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢"""
        try:
            # GitHub APIã‚’ä½¿ç”¨ã—ã¦ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—
            # raw.githubusercontent.com URLã‚’API URLã«å¤‰æ›
            if "raw.githubusercontent.com" in base_url:
                # URLã‚’è§£æã—ã¦APIç”¨ã«å¤‰æ›
                # https://raw.githubusercontent.com/kentashimoji/kozu-pick/main/47okinawa
                # -> https://api.github.com/repos/kentashimoji/kozu-pick/contents/47okinawa
                parts = base_url.replace('https://raw.githubusercontent.com/', '').split('/')
                username = parts[0]
                repo = parts[1]
                branch = parts[2]  # main
                folder_path = '/'.join(parts[3:])  # 47okinawa
                
                api_url = f"https://api.GitHub.com/repos/{username}/{repo}/contents/{folder_path}"
                
                headers = {'User-Agent': 'PrefectureCitySelector/33.0'}
                response = requests.get(api_url, headers=headers, timeout=30)
                response.raise_for_status()
                
                files_data = response.json()
                
                # æ¤œç´¢ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ä½œæˆ
                search_code = f"{prefecture_code}{city_code}"
                
                # å¯¾å¿œã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­
                extensions = ['.csv', '.xlsx', '.xls', '.txt', '.json']
                found_files = []
                
                for file_info in files_data:
                    if file_info['type'] == 'file':
                        file_name = file_info['name']
                        file_ext = os.path.splitext(file_name)[1].lower()
                        
                        # ãƒ•ã‚¡ã‚¤ãƒ«åã«å›£ä½“ã‚³ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã€å¯¾å¿œã™ã‚‹æ‹¡å¼µå­ã‹ãƒã‚§ãƒƒã‚¯
                        if search_code in file_name and file_ext in extensions:
                            found_files.append({
                                'name': file_name,
                                'download_url': file_info['download_url'],
                                'size': file_info['size']
                            })
                
                return found_files
            else:
                st.error("GitHub Raw URLã®å½¢å¼ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“")
                return []
                
        except requests.RequestException as e:
            st.error(f"GitHub APIã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
            return []
        except Exception as e:
            st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            return []
    
    def group_shapefile_sets(self, files):
        """Shapefileã®é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚»ãƒƒãƒˆã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–"""
        shapefile_sets = {}
        
        for file_path in files:
            base_name = os.path.splitext(file_path)[0]
            ext = os.path.splitext(file_path)[1].lower()
            
            if ext in ['.shp', '.shx', '.prj', '.dbf', '.cpg']:
                if base_name not in shapefile_sets:
                    shapefile_sets[base_name] = []
                shapefile_sets[base_name].append(file_path)
        
        # å®Œå…¨ãªShapefileã‚»ãƒƒãƒˆï¼ˆ.shp, .shx, .dbfãŒå…¨ã¦æƒã£ã¦ã„ã‚‹ï¼‰ã®ã¿ã‚’è¿”ã™
        complete_sets = {}
        for base_name, file_list in shapefile_sets.items():
            extensions = [os.path.splitext(f)[1].lower() for f in file_list]
            if '.shp' in extensions and '.shx' in extensions and '.dbf' in extensions:
                complete_sets[base_name] = file_list
        
        return complete_sets
    
    def extract_zip_file(self, zip_path, temp_dir):
        """ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«å±•é–‹"""
        try:
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                zip_ref.extractall(temp_dir)
            
            # å±•é–‹ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰GISãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
            extracted_files = []
            for root, dirs, files in os.walk(temp_dir):
                for file in files:
                    if file.lower().endswith(('.shp', '.kml', '.geojson')):
                        extracted_files.append(os.path.join(root, file))
            
            return extracted_files
        except Exception as e:
            st.error(f"ZIPãƒ•ã‚¡ã‚¤ãƒ«ã®å±•é–‹ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
            return []
    
    def load_area_data_from_url(self, file_url, file_name):
        """GitHubã‹ã‚‰ç›´æ¥ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦å¤§å­—ãƒ»ä¸ç›®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            headers = {'User-Agent': 'PrefectureCitySelector/33.0'}
            response = requests.get(file_url, headers=headers, timeout=30)
            response.raise_for_status()
            
            # ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­ã«åŸºã¥ã„ã¦èª­ã¿è¾¼ã¿æ–¹æ³•ã‚’æ±ºå®š
            file_ext = os.path.splitext(file_name)[1].lower()
            df = None
            
            if file_ext in ['.xlsx', '.xls']:
                # Excelãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
                excel_data = BytesIO(response.content)
                df = pd.read_excel(excel_data)
                
            elif file_ext == '.csv':
                # CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ï¼ˆè¤‡æ•°ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å¯¾å¿œï¼‰
                content = response.content
                encodings = ['utf-8', 'utf-8-sig', 'shift_jis', 'cp932']
                
                for encoding in encodings:
                    try:
                        df = pd.read_csv(BytesIO(content), encoding=encoding)
                        break
                    except UnicodeDecodeError:
                        continue
                
                if df is None:
                    st.error("CSVãƒ•ã‚¡ã‚¤ãƒ«ã®æ–‡å­—ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’èª­ã¿å–ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
                    return False
                    
            elif file_ext == '.txt':
                # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ï¼ˆCSVå½¢å¼ã¨ã—ã¦å‡¦ç†ï¼‰
                content = response.content
                encodings = ['utf-8', 'utf-8-sig', 'shift_jis', 'cp932']
                
                for encoding in encodings:
                    try:
                        df = pd.read_csv(BytesIO(content), encoding=encoding, sep=None, engine='python')
                        break
                    except UnicodeDecodeError:
                        continue
                
                if df is None:
                    st.error("ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
                    return False
                    
            elif file_ext == '.json':
                # JSONãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
                import json
                json_data = json.loads(response.text)
                df = pd.json_normalize(json_data)
                
            else:
                st.error(f"å¯¾å¿œã—ã¦ã„ãªã„ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã§ã™: {file_ext}")
                return False
            
            if df is None or df.empty:
                st.error("ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸ")
                return False
            
            # å¤§å­—ãƒ»ä¸ç›®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
            area_data = self.extract_area_from_dataframe(df)
            
            if not area_data:
                st.error("å¤§å­—ãƒ»ä¸ç›®æƒ…å ±ã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ")
                # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤º
                st.info(f"åˆ©ç”¨å¯èƒ½ãªåˆ—: {list(df.columns)}")
                if len(df) > 0:
                    st.info(f"ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«: {df.head(1).to_dict()}")
                return False
            
            st.session_state.area_data = area_data
            st.session_state.selected_file_path = file_name
            
            # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’è¡¨ç¤º
            st.info(f"ğŸ“Š èª­ã¿è¾¼ã¿å®Œäº†: {len(df)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã€{len(area_data)}å€‹ã®å¤§å­—ã‚’æ¤œå‡º")
            
            return True
            
        except Exception as e:
            st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
            return False
    
    def extract_area_from_dataframe(self, df):
        """ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰å¤§å­—ãƒ»ä¸ç›®ã‚’æŠ½å‡º"""
        # å¯èƒ½æ€§ã®ã‚ã‚‹åˆ—åãƒ‘ã‚¿ãƒ¼ãƒ³
        oaza_patterns = ['å¤§å­—', 'ãŠãŠã‚ã–', 'ã‚ªã‚ªã‚¢ã‚¶', 'OAZA', 'oaza', 'å­—', 'ç”ºå', 'TOWN', 'town', 'å¤§å­—å']
        chome_patterns = ['ä¸ç›®', 'ã¡ã‚‡ã†ã‚', 'ãƒãƒ§ã‚¦ãƒ¡', 'CHOME', 'chome', 'ä¸', 'ç•ªåœ°', 'ä¸ç›®å']
        address_patterns = ['ä½æ‰€', 'address', 'ADDRESS', 'æ‰€åœ¨åœ°', 'åœ°å', 'name', 'NAME']
        
        area_data = {}
        
        # åˆ—åã‚’å–å¾—
        columns = [str(col).lower() for col in df.columns]
        
        # å¤§å­—ãƒ»ä¸ç›®ã®å°‚ç”¨åˆ—ã‚’æ¤œç´¢
        oaza_col = None
        chome_col = None
        address_col = None
        
        for col in df.columns:
            col_lower = str(col).lower()
            
            # å¤§å­—åˆ—ã®æ¤œç´¢
            if not oaza_col and any(pattern.lower() in col_lower for pattern in oaza_patterns):
                oaza_col = col
            
            # ä¸ç›®åˆ—ã®æ¤œç´¢
            if not chome_col and any(pattern.lower() in col_lower for pattern in chome_patterns):
                chome_col = col
            
            # ä½æ‰€åˆ—ã®æ¤œç´¢
            if not address_col and any(pattern.lower() in col_lower for pattern in address_patterns):
                address_col = col
        
        # ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
        if oaza_col:
            # å¤§å­—ã®å°‚ç”¨åˆ—ãŒã‚ã‚‹å ´åˆ
            for _, row in df.iterrows():
                oaza = str(row[oaza_col]) if pd.notna(row[oaza_col]) else ""
                oaza = oaza.strip()
                
                if oaza and oaza != 'nan':
                    if oaza not in area_data:
                        area_data[oaza] = set()
                    
                    # ä¸ç›®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆ
                    if chome_col and pd.notna(row[chome_col]):
                        chome = str(row[chome_col]).strip()
                        if chome and chome != 'nan':
                            area_data[oaza].add(chome)
        
        elif address_col:
            # ä½æ‰€åˆ—ã‹ã‚‰æŠ½å‡º
            for _, row in df.iterrows():
                address = str(row[address_col]) if pd.notna(row[address_col]) else ""
                
                # æ­£è¦è¡¨ç¾ã§å¤§å­—ãƒ»ä¸ç›®ã‚’æŠ½å‡º
                oaza_matches = re.findall(r'å¤§å­—(.+?)(?:[0-9]|ä¸ç›®|ç•ªåœ°|$)', address)
                chome_matches = re.findall(r'([0-9]+ä¸ç›®)', address)
                
                for oaza_match in oaza_matches:
                    oaza = oaza_match.strip()
                    if oaza:
                        if oaza not in area_data:
                            area_data[oaza] = set()
                        
                        for chome in chome_matches:
                            area_data[oaza].add(chome)
        
        else:
            # å…¨ã¦ã®åˆ—ã‹ã‚‰ä½æ‰€ã‚‰ã—ã„æƒ…å ±ã‚’æŠ½å‡º
            for col in df.columns:
                if df[col].dtype == 'object':  # æ–‡å­—åˆ—å‹ã®åˆ—ã®ã¿
                    for _, row in df.iterrows():
                        value = str(row[col]) if pd.notna(row[col]) else ""
                        
                        # å¤§å­—ãƒ»ä¸ç›®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œç´¢
                        if 'å¤§å­—' in value or 'ä¸ç›®' in value:
                            oaza_matches = re.findall(r'å¤§å­—(.+?)(?:[0-9]|ä¸ç›®|ç•ªåœ°|$)', value)
                            chome_matches = re.findall(r'([0-9]+ä¸ç›®)', value)
                            
                            for oaza_match in oaza_matches:
                                oaza = oaza_match.strip()
                                if oaza:
                                    if oaza not in area_data:
                                        area_data[oaza] = set()
                                    
                                    for chome in chome_matches:
                                        area_data[oaza].add(chome)
        
        # Setã‚’Listã«å¤‰æ›ã—ã¦ã‚½ãƒ¼ãƒˆ
        for oaza in area_data:
            area_data[oaza] = sorted(list(area_data[oaza]))
        
        return area_data
    
    def get_files_from_github_folder(self, folder_url, file_extensions=None):
        """GitHubãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—"""
        if file_extensions is None:
            file_extensions = ['.zip', '.shp', '.shx', '.prj', '.dbf', '.cpg', '.kml']
        
        try:
            # GitHub URLã‚’è§£æ
            if 'raw.githubusercontent.com' in folder_url:
                # raw URLã‚’API URLã«å¤‰æ›
                parts = folder_url.replace('https://raw.githubusercontent.com/', '').split('/')
                username = parts[0]
                repo = parts[1]
                branch = parts[2]
                folder_path = '/'.join(parts[3:])
            elif 'github.com' in folder_url:
                # github.com URLã‚’API URLã«å¤‰æ›
                parts = folder_url.replace('https://github.com/', '').split('/')
                if len(parts) < 2:
                    raise Exception("ç„¡åŠ¹ãªGitHub URLã§ã™")
                
                username = parts[0]
                repo = parts[1]
                
                if len(parts) > 3 and parts[2] == 'tree':
                    branch = parts[3]
                    folder_path = '/'.join(parts[4:]) if len(parts) > 4 else ''
                else:
                    branch = 'main'
                    folder_path = '/'.join(parts[2:]) if len(parts) > 2 else ''
            else:
                raise Exception("GitHubã®URLã§ã¯ã‚ã‚Šã¾ã›ã‚“")
            
            # GitHub API URLæ§‹ç¯‰
            api_url = f"https://api.github.com/repos/{username}/{repo}/contents/{folder_path}"
            if branch != 'main':
                api_url += f"?ref={branch}"
            
            headers = {'User-Agent': 'PrefectureCitySelector/39.0'}
            response = requests.get(api_url, headers=headers, timeout=30)
            
            if response.status_code == 403:
                st.warning("âš ï¸ GitHub APIã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚ä»£æ›¿æ–¹æ³•ã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—ã—ã¾ã™...")
                return self._get_github_files_alternative(username, repo, branch, folder_path, file_extensions)
            
            response.raise_for_status()
            files_data = response.json()
            
            files = []
            shapefile_sets = {}
            
            for item in files_data:
                if item['type'] == 'file':
                    file_name = item['name']
                    file_ext = os.path.splitext(file_name)[1].lower()
                    
                    if any(file_name.lower().endswith(ext.lower()) for ext in file_extensions):
                        file_info = {
                            'name': file_name,
                            'url': item['download_url'],
                            'size': item.get('size', 0),
                            'extension': file_ext,
                            'description': f"GISãƒ•ã‚¡ã‚¤ãƒ« ({item.get('size', 0)} bytes)"
                        }
                        files.append(file_info)
                        
                        # Shapefileã‚»ãƒƒãƒˆã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
                        if file_ext in ['.shp', '.shx', '.prj', '.dbf', '.cpg']:
                            base_name = os.path.splitext(file_name)[0]
                            if base_name not in shapefile_sets:
                                shapefile_sets[base_name] = []
                            shapefile_sets[base_name].append(file_info)
            
            return files, shapefile_sets
            
        except Exception as e:
            st.error(f"GitHubãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰ã®ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
            return [], {}
    
    def _get_github_files_alternative(self, username, repo, branch, folder_path, file_extensions):
        """GitHub APIãŒä½¿ãˆãªã„å ´åˆã®ä»£æ›¿æ–¹æ³•"""
        try:
            from bs4 import BeautifulSoup
            
            web_url = f"https://github.com/{username}/{repo}/tree/{branch}/{folder_path}"
            response = requests.get(web_url, timeout=30)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            files = []
            
            # GitHubã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒªãƒ³ã‚¯ã‚’æ¤œç´¢
            file_links = soup.find_all('a', href=True)
            
            for link in file_links:
                href = link.get('href', '')
                link_text = link.get_text().strip()
                
                if '/blob/' in href and any(link_text.lower().endswith(ext.lower()) for ext in file_extensions):
                    raw_url = href.replace('github.com', 'raw.githubusercontent.com').replace('/blob/', '/')
                    if not raw_url.startswith('http'):
                        raw_url = f"https://raw.githubusercontent.com{raw_url}"
                    
                    files.append({
                        'name': link_text,
                        'url': raw_url,
                        'size': None,
                        'description': f"GitHubãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆä»£æ›¿å–å¾—ï¼‰"
                    })
            
            return files
            
        except Exception as e:
            raise Exception(f"GitHubä»£æ›¿å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    def get_chome_options(self, area_data, selected_oaza):
        """æŒ‡å®šã•ã‚ŒãŸå¤§å­—åã«å¯¾å¿œã™ã‚‹ä¸ç›®ã®é¸æŠè‚¢ã‚’å–å¾—"""
        try:
            if selected_oaza in area_data:
                chome_list = area_data[selected_oaza]
                if chome_list:
                    return chome_list
            return None
        except Exception as e:
            st.error(f"ä¸ç›®åå–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None
    
    def render_main_page(self):
        """ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ã‚’æç”»"""
        st.title("ğŸ›ï¸ éƒ½é“åºœçœŒãƒ»å¸‚åŒºç”ºæ‘é¸æŠãƒ„ãƒ¼ãƒ« v39.0")
        
        col1, col2, col3 = st.columns([2, 1, 1])
        with col1:
            st.markdown("**GitHub Excelãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä½œæˆ**")
        with col2:
            st.metric("ãƒãƒ¼ã‚¸ãƒ§ãƒ³", "39.0")
        with col3:
            st.metric("ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ", "Streamlit + GitHub")
        
        st.markdown("---")
        
        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚»ã‚¯ã‚·ãƒ§ãƒ³
        st.header("ğŸ“¡ ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹è¨­å®š")
        
        default_url = "https://raw.githubusercontent.com/USERNAME/REPOSITORY/main/000925835.xlsx"
        url = st.text_input(
            "GitHub Excelãƒ•ã‚¡ã‚¤ãƒ«URL:",
            value=st.session_state.current_url or default_url,
            help="GitHubã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ãã€'Raw'ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ãŸæ™‚ã®URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"
        )
        
        col1, col2, col3 = st.columns([1, 1, 2])
        with col1:
            if st.button("ğŸ”„ ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿", type="primary"):
                self.load_data_from_github(url)
        
        with col2:
            if st.button("ğŸ—‘ï¸ ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢"):
                st.session_state.prefecture_data = {}
                st.session_state.prefecture_codes = {}
                st.session_state.city_codes = {}
                st.session_state.data_loaded = False
                st.session_state.current_url = ""
                st.session_state.selected_prefecture = ""
                st.session_state.selected_city = ""
                st.session_state.selected_file_path = ""
                st.session_state.area_data = {}
                st.session_state.selected_oaza = ""
                st.session_state.selected_chome = ""
                st.success("ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ")
                st.experimental_rerun()
        
        # ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã‚‹å ´åˆã®é¸æŠUI
        if st.session_state.data_loaded and st.session_state.prefecture_data:
            st.markdown("---")
            st.header("ğŸ¯ åœ°åŸŸé¸æŠ")
            
            col1, col2 = st.columns(2)
            
            with col1:
                # éƒ½é“åºœçœŒã¯æ—¢ã«ã‚½ãƒ¼ãƒˆæ¸ˆã¿ï¼ˆæ²–ç¸„çœŒãŒæœ€åˆã€ãã®å¾Œå›£ä½“ã‚³ãƒ¼ãƒ‰é †ï¼‰
                prefectures = list(st.session_state.prefecture_data.keys())
                prefecture_options = [f"{p} ({len(st.session_state.prefecture_data[p])}å¸‚åŒºç”ºæ‘)" 
                                    for p in prefectures]
                
                selected_prefecture_display = st.selectbox(
                    "éƒ½é“åºœçœŒã‚’é¸æŠã—ã¦ãã ã•ã„:",
                    ["é¸æŠã—ã¦ãã ã•ã„"] + prefecture_options,
                    key="prefecture_select"
                )
                
                if selected_prefecture_display != "é¸æŠã—ã¦ãã ã•ã„":
                    prefecture_name = selected_prefecture_display.split(' (')[0]
                    st.session_state.selected_prefecture = prefecture_name
            
            with col2:
                if st.session_state.selected_prefecture:
                    # å¸‚åŒºç”ºæ‘ã¯æ—¢ã«å›£ä½“ã‚³ãƒ¼ãƒ‰é †ã§ã‚½ãƒ¼ãƒˆæ¸ˆã¿
                    cities_dict = st.session_state.prefecture_data[st.session_state.selected_prefecture]
                    cities = list(cities_dict.keys())
                    
                    selected_city = st.selectbox(
                        "å¸‚åŒºç”ºæ‘ã‚’é¸æŠã—ã¦ãã ã•ã„:",
                        ["é¸æŠã—ã¦ãã ã•ã„"] + cities,
                        key="city_select"
                    )
                    
                    if selected_city != "é¸æŠã—ã¦ãã ã•ã„":
                        st.session_state.selected_city = selected_city
                else:
                    st.selectbox(
                        "å¸‚åŒºç”ºæ‘ã‚’é¸æŠã—ã¦ãã ã•ã„:",
                        ["ã¾ãšéƒ½é“åºœçœŒã‚’é¸æŠã—ã¦ãã ã•ã„"],
                        disabled=True
                    )
            
            # é¸æŠçµæœã®è¡¨ç¤º
            if st.session_state.selected_prefecture and st.session_state.selected_city:
                st.markdown("---")
                st.header("ğŸ“ é¸æŠçµæœ")
                
                # ã‚³ãƒ¼ãƒ‰æƒ…å ±ã‚’å–å¾—
                prefecture_code = st.session_state.prefecture_codes.get(st.session_state.selected_prefecture, "ä¸æ˜")
                city_key = f"{st.session_state.selected_prefecture}_{st.session_state.selected_city}"
                city_info = st.session_state.city_codes.get(city_key, {})
                city_code = city_info.get('city_code', "ä¸æ˜")
                full_code = city_info.get('full_code', "ä¸æ˜")
                
                result_data = {
                    "éƒ½é“åºœçœŒ": st.session_state.selected_prefecture,
                    "éƒ½é“åºœçœŒã‚³ãƒ¼ãƒ‰": prefecture_code,
                    "å¸‚åŒºç”ºæ‘": st.session_state.selected_city,
                    "å¸‚åŒºç”ºæ‘ã‚³ãƒ¼ãƒ‰": city_code,
                    "å®Œå…¨ãªä½æ‰€": f"{st.session_state.selected_prefecture}{st.session_state.selected_city}",
                    "å›£ä½“ã‚³ãƒ¼ãƒ‰ï¼ˆå®Œå…¨ï¼‰": full_code,
                    "é¸æŠæ—¥æ™‚": datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S'),
                    "ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹": st.session_state.current_url[:60] + "..." if len(st.session_state.current_url) > 60 else st.session_state.current_url
                }
                
                col1, col2 = st.columns([2, 1])
                
                with col1:
                    # é‡è¦ãªæƒ…å ±ã‚’å¼·èª¿è¡¨ç¤º
                    st.subheader("ğŸ›ï¸ åŸºæœ¬æƒ…å ±")
                    st.write(f"**éƒ½é“åºœçœŒ:** {result_data['éƒ½é“åºœçœŒ']}")
                    st.write(f"**å¸‚åŒºç”ºæ‘:** {result_data['å¸‚åŒºç”ºæ‘']}")
                    st.write(f"**å®Œå…¨ãªä½æ‰€:** {result_data['å®Œå…¨ãªä½æ‰€']}")
                    
                    st.subheader("ğŸ”¢ ã‚³ãƒ¼ãƒ‰æƒ…å ±")
                    st.write(f"**éƒ½é“åºœçœŒã‚³ãƒ¼ãƒ‰:** {result_data['éƒ½é“åºœçœŒã‚³ãƒ¼ãƒ‰']}")
                    st.write(f"**å¸‚åŒºç”ºæ‘ã‚³ãƒ¼ãƒ‰:** {result_data['å¸‚åŒºç”ºæ‘ã‚³ãƒ¼ãƒ‰']}")
                    st.write(f"**å›£ä½“ã‚³ãƒ¼ãƒ‰ï¼ˆå®Œå…¨ï¼‰:** {result_data['å›£ä½“ã‚³ãƒ¼ãƒ‰ï¼ˆå®Œå…¨ï¼‰']}")
                    
                    st.subheader("â„¹ï¸ ãã®ä»–")
                    st.write(f"**é¸æŠæ—¥æ™‚:** {result_data['é¸æŠæ—¥æ™‚']}")
                    if st.session_state.current_url:
                        st.write(f"**ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹:** {result_data['ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹']}")
                
                with col2:
                    if st.button("ğŸ“‹ çµæœã‚’ã‚³ãƒ”ãƒ¼"):
                        result_text = "\n".join([f"{k}: {v}" for k, v in result_data.items()])
                        st.code(result_text)
                        st.success("çµæœã‚’è¡¨ç¤ºã—ã¾ã—ãŸã€‚ä¸Šè¨˜ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚³ãƒ”ãƒ¼ã—ã¦ãã ã•ã„ã€‚")
                
                # å¤§å­—ãƒ»ä¸ç›®é¸æŠã‚»ã‚¯ã‚·ãƒ§ãƒ³
                if prefecture_code != "ä¸æ˜" and city_code != "ä¸æ˜":
                    st.markdown("---")
                    st.header("ğŸ˜ï¸ è©³ç´°ä½æ‰€é¸æŠï¼ˆGISãƒ•ã‚¡ã‚¤ãƒ«å¯¾å¿œï¼‰")
                    
                    # ãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹å…¥åŠ›
                    folder_path = st.text_input(
                        "ğŸ“ GISãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢ãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹:",
                        value=st.session_state.folder_path,
                        help="å¤§å­—ãƒ»ä¸ç›®ãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã‚‹GISãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆZIPã€Shapefileã€KMLï¼‰ãŒã‚ã‚‹ãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"
                    )
                    
                    col1, col2 = st.columns([1, 2])
                    
                    with col1:
                        if st.button("ğŸ” GISãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢"):
                            if folder_path:
                                st.session_state.folder_path = folder_path
                                files, shapefile_sets = self.find_files_by_code(folder_path, prefecture_code, city_code)
                                
                                if files or shapefile_sets:
                                    total_files = len(files) + len(shapefile_sets)
                                    st.success(f"âœ… {total_files}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«/ã‚»ãƒƒãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
                                    
                                    # ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠ
                                    selected_file_option = st.selectbox(
                                        "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„:",
                                        file_options,
                                        key="file_select"
                                    )
                                    
                                    if selected_file_option != "é¸æŠã—ã¦ãã ã•ã„":
                                        selected_file_path = file_mapping[selected_file_option]
                                        
                                        # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’è¡¨ç¤º
                                        file_info = f"**é¸æŠã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«:** {os.path.basename(selected_file_path)}"
                                        if selected_file_option.startswith("ğŸ—ºï¸"):
                                            # Shapefileã‚»ãƒƒãƒˆã®å ´åˆã€æ§‹æˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¡¨ç¤º
                                            base_name = os.path.splitext(selected_file_path)[0]
                                            related_files = shapefile_sets.get(base_name, [])
                                            if related_files:
                                                file_info += f"\n\n**æ§‹æˆãƒ•ã‚¡ã‚¤ãƒ«:**"
                                                for rf in sorted(related_files):
                                                    file_info += f"\nâ€¢ {os.path.basename(rf)}"
                                        
                                        st.info(file_info)
                                        
                                        if st.button("ğŸ“– GISãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"):
                                            with st.spinner("GISãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™..."):
                                                if self.load_area_data(selected_file_path):
                                                    st.success("âœ… GISãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ãŒå®Œäº†ã—ã¾ã—ãŸ")
                                                    st.experimental_rerun()
                                else:
                                    st.warning(f"âš ï¸ å›£ä½“ã‚³ãƒ¼ãƒ‰ã€Œ{prefecture_code}{city_code}ã€ã‚’å«ã‚€GISãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                                    st.info("**å¯¾å¿œãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼:** ZIP, Shapefile(.shp), KML, ãŠã‚ˆã³é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«(.shx, .prj, .dbf, .cpg)")
                            else:
                                st.error("ãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
                    
                    with col2:
                        # å¤§å­—ãƒ»ä¸ç›®é¸æŠUI
                        if st.session_state.area_data:
                            st.subheader("ğŸ˜ï¸ å¤§å­—ãƒ»ä¸ç›®é¸æŠ")
                            
                            # å¤§å­—é¸æŠ
                            oaza_list = sorted(st.session_state.area_data.keys())
                            selected_oaza = st.selectbox(
                                "å¤§å­—ã‚’é¸æŠã—ã¦ãã ã•ã„:",
                                ["é¸æŠã—ã¦ãã ã•ã„"] + oaza_list,
                                key="oaza_select"
                            )
                            
                            if selected_oaza != "é¸æŠã—ã¦ãã ã•ã„":
                                st.session_state.selected_oaza = selected_oaza
                                
                                # ä¸ç›®é¸æŠ
                                chome_list = st.session_state.area_data.get(selected_oaza, [])
                                if chome_list:
                                    selected_chome = st.selectbox(
                                        "ä¸ç›®ã‚’é¸æŠã—ã¦ãã ã•ã„:",
                                        ["é¸æŠã—ã¦ãã ã•ã„"] + chome_list,
                                        key="chome_select"
                                    )
                                    
                                    if selected_chome != "é¸æŠã—ã¦ãã ã•ã„":
                                        st.session_state.selected_chome = selected_chome
                                        
                                        # å®Œå…¨ãªä½æ‰€è¡¨ç¤º
                                        complete_address = f"{st.session_state.selected_prefecture}{st.session_state.selected_city}{selected_oaza}{selected_chome}"
                                        
                                        st.success("ğŸ¯ å®Œå…¨ãªä½æ‰€ãŒé¸æŠã•ã‚Œã¾ã—ãŸ")
                                        st.write(f"**å®Œå…¨ãªä½æ‰€:** {complete_address}")
                                        
                                        # è©³ç´°çµæœ
                                        detailed_result = {
                                            "éƒ½é“åºœçœŒ": st.session_state.selected_prefecture,
                                            "éƒ½é“åºœçœŒã‚³ãƒ¼ãƒ‰": prefecture_code,
                                            "å¸‚åŒºç”ºæ‘": st.session_state.selected_city,
                                            "å¸‚åŒºç”ºæ‘ã‚³ãƒ¼ãƒ‰": city_code,
                                            "å¤§å­—": selected_oaza,
                                            "ä¸ç›®": selected_chome,
                                            "å®Œå…¨ãªä½æ‰€": complete_address,
                                            "å›£ä½“ã‚³ãƒ¼ãƒ‰": full_code,
                                            "ä½¿ç”¨ãƒ•ã‚¡ã‚¤ãƒ«": os.path.basename(st.session_state.selected_file_path),
                                            "é¸æŠæ—¥æ™‚": datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')
                                        }
                                        
                                        if st.button("ğŸ“‹ è©³ç´°çµæœã‚’ã‚³ãƒ”ãƒ¼"):
                                            detailed_text = "\n".join([f"{k}: {v}" for k, v in detailed_result.items()])
                                            st.code(detailed_text)
                                            st.success("è©³ç´°çµæœã‚’è¡¨ç¤ºã—ã¾ã—ãŸ")
                                else:
                                    st.info("é¸æŠã•ã‚ŒãŸå¤§å­—ã«ä¸ç›®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                        else:
                            st.info("ã¾ãšGISãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢ãƒ»èª­ã¿è¾¼ã¿ã—ã¦ãã ã•ã„")
    
    def render_data_page(self):
        """ãƒ‡ãƒ¼ã‚¿ç®¡ç†ãƒšãƒ¼ã‚¸ã‚’æç”»"""
        st.title("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ç®¡ç†")
        
        if not st.session_state.data_loaded or not st.session_state.prefecture_data:
            st.warning("ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ã§ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚")
            return
        
        # ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿çŠ¶æ…‹ã®ã¿è¡¨ç¤º
        st.header("â„¹ï¸ ç¾åœ¨ã®çŠ¶æ…‹")
        
        st.success("âœ… ãƒ‡ãƒ¼ã‚¿ãŒæ­£å¸¸ã«èª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã™")
        
        if st.session_state.current_url:
            st.info(f"ğŸ“¡ ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹: {st.session_state.current_url}")
        
        # GISãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±
        if st.session_state.selected_file_path:
            st.info(f"ğŸ—ºï¸ èª­ã¿è¾¼ã¿æ¸ˆã¿GISãƒ•ã‚¡ã‚¤ãƒ«: {os.path.basename(st.session_state.selected_file_path)}")
        
        # ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªã‚¢æ©Ÿèƒ½ã®ã¿
        st.header("ğŸ—‘ï¸ ãƒ‡ãƒ¼ã‚¿ç®¡ç†")
        
        if st.button("ğŸ—‘ï¸ èª­ã¿è¾¼ã¾ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢", type="secondary"):
            if st.session_state.data_loaded:
                st.session_state.prefecture_data = {}
                st.session_state.prefecture_codes = {}
                st.session_state.city_codes = {}
                st.session_state.data_loaded = False
                st.session_state.current_url = ""
                st.session_state.selected_prefecture = ""
                st.session_state.selected_city = ""
                st.session_state.selected_file_path = ""
                st.session_state.area_data = {}
                st.session_state.selected_oaza = ""
                st.session_state.selected_chome = ""
                st.success("ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ")
                st.experimental_rerun()
            else:
                st.warning("ã‚¯ãƒªã‚¢ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
    
    def render_about_page(self):
        """æƒ…å ±ãƒšãƒ¼ã‚¸ã‚’æç”»"""
        st.title("â„¹ï¸ ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æƒ…å ±")
        
        st.markdown("""
        ## ğŸ›ï¸ éƒ½é“åºœçœŒãƒ»å¸‚åŒºç”ºæ‘é¸æŠãƒ„ãƒ¼ãƒ« v39.0 (GitHubé€£æºç‰ˆ)
        
        ### æ¦‚è¦
        GitHubã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸExcelãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ—¥æœ¬ã®éƒ½é“åºœçœŒãƒ»å¸‚åŒºç”ºæ‘ãƒ‡ãƒ¼ã‚¿ã‚’
        èª­ã¿è¾¼ã¿ã€ã•ã‚‰ã«GitHubãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰è‡ªå‹•çš„ã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢ã—ã¦å¤§å­—ãƒ»ä¸ç›®ãƒ¬ãƒ™ãƒ«ã¾ã§ã®
        è©³ç´°ãªä½æ‰€é¸æŠã‚’å¯èƒ½ã«ã™ã‚‹Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã™ã€‚
        
        ### ä¸»ãªæ©Ÿèƒ½
        âœ… **GitHubå¯¾å¿œ**: GitHubä¸Šã®Excelãƒ•ã‚¡ã‚¤ãƒ«ã®ç›´æ¥èª­ã¿è¾¼ã¿  
        âœ… **éšå±¤é¸æŠ**: éƒ½é“åºœçœŒé¸æŠã«ã‚ˆã‚‹å¸‚åŒºç”ºæ‘ã®çµã‚Šè¾¼ã¿  
        âœ… **GitHubé€£æº**: å›£ä½“ã‚³ãƒ¼ãƒ‰ã«ã‚ˆã‚‹ä½æ‰€ãƒ•ã‚¡ã‚¤ãƒ«ã®è‡ªå‹•æ¤œç´¢ãƒ»èª­ã¿è¾¼ã¿  
        âœ… **å›£ä½“ã‚³ãƒ¼ãƒ‰**: éƒ½é“åºœçœŒã‚³ãƒ¼ãƒ‰ãƒ»å¸‚åŒºç”ºæ‘ã‚³ãƒ¼ãƒ‰ã®è¡¨ç¤º  
        âœ… **è©³ç´°ä½æ‰€**: å¤§å­—ãƒ»ä¸ç›®ãƒ¬ãƒ™ãƒ«ã¾ã§ã®å®Œå…¨ãªä½æ‰€é¸æŠ  
        âœ… **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ **: é¸æŠçµæœã®å³æ™‚è¡¨ç¤º  
        âœ… **ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–**: ãƒ¢ãƒã‚¤ãƒ«ãƒ»ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—å¯¾å¿œ  
        âœ… **ã‚·ãƒ³ãƒ—ãƒ«**: ç›´æ„Ÿçš„ã§ä½¿ã„ã‚„ã™ã„ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
        
        ### å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒª
        ```bash
        pip install streamlit pandas openpyxl requests geopandas fiona lxml
        ```
        
        ### å®Ÿè¡Œæ–¹æ³•
        ```bash
        streamlit run prefecture_city_selector_streamlit.py
        ```
        
        ### GitHub Raw URLã®å–å¾—æ–¹æ³•
        1. GitHubã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã
        2. ã€ŒRawã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯  
        3. ãƒ–ãƒ©ã‚¦ã‚¶ã®ã‚¢ãƒ‰ãƒ¬ã‚¹ãƒãƒ¼ã‹ã‚‰URLã‚’ã‚³ãƒ”ãƒ¼
        
        ### å¯¾å¿œãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼
        **åŸºæœ¬ãƒ‡ãƒ¼ã‚¿:**
        - Excel (.xlsx, .xls)
        - CSV (.csv)
        
        **GitHub GISãƒ‡ãƒ¼ã‚¿:**
        - **ZIP**: åœ§ç¸®ã•ã‚ŒãŸShapefileã‚»ãƒƒãƒˆ
        - **Shapefile**: .shp, .shx, .prj, .dbf, .cpg
        - **KML**: GoogleEarthå½¢å¼ã®GISãƒ‡ãƒ¼ã‚¿
        
        ### GitHubãƒ•ã‚©ãƒ«ãƒ€é€£æº
        ```
        æŒ‡å®šãƒ•ã‚©ãƒ«ãƒ€: https://raw.githubusercontent.com/kentashimoji/kozu-pick/main/47okinawa
        
        æ¤œç´¢ãƒ‘ã‚¿ãƒ¼ãƒ³: [éƒ½é“åºœçœŒã‚³ãƒ¼ãƒ‰][å¸‚åŒºç”ºæ‘ã‚³ãƒ¼ãƒ‰]
        ä¾‹: 47201 (æ²–ç¸„çœŒé‚£è¦‡å¸‚)
        
        å¯¾å¿œå½¢å¼: ZIP, SHP, KML, ãŠã‚ˆã³Shapefileé–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«
        ```
        
        ### å›£ä½“ã‚³ãƒ¼ãƒ‰ä½“ç³»
        ```
        å›£ä½“ã‚³ãƒ¼ãƒ‰ï¼ˆ6æ¡ï¼‰ã®æ§‹é€ :
        472016 ã®å ´åˆ:
        â”œâ”€ 47:   éƒ½é“åºœçœŒã‚³ãƒ¼ãƒ‰ï¼ˆæ²–ç¸„çœŒï¼‰
        â”œâ”€ 201:  å¸‚åŒºç”ºæ‘ã‚³ãƒ¼ãƒ‰ï¼ˆé‚£è¦‡å¸‚ï¼‰
        â””â”€ 6:    ãƒã‚§ãƒƒã‚¯ãƒ‡ã‚¸ãƒƒãƒˆ
        ```
        
        ### ä½¿ç”¨æ‰‹é †
        1. **åŸºæœ¬é¸æŠ**: GitHub URLã‚’å…¥åŠ›ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
        2. **åœ°åŸŸé¸æŠ**: éƒ½é“åºœçœŒãƒ»å¸‚åŒºç”ºæ‘ã‚’é¸æŠ
        3. **GISãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢**: GitHubã‹ã‚‰å›£ä½“ã‚³ãƒ¼ãƒ‰ã§GISãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•æ¤œç´¢
        4. **è©³ç´°é¸æŠ**: è¦‹ã¤ã‹ã£ãŸGISãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å¤§å­—ãƒ»ä¸ç›®ã‚’é¸æŠ
        5. **çµæœå–å¾—**: å®Œå…¨ãªä½æ‰€æƒ…å ±ã¨å›£ä½“ã‚³ãƒ¼ãƒ‰ã‚’å–å¾—
        
        ### æ³¨æ„äº‹é …
        - ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šãŒå¿…è¦ã§ã™
        - GISæ©Ÿèƒ½ã«ã¯GeoPandasãŒå¿…è¦ã§ã™
        - ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãƒªãƒã‚¸ãƒˆãƒªã®å ´åˆã¯é©åˆ‡ãªã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ãŒå¿…è¦ã§ã™
        - å¤§ããªGISãƒ•ã‚¡ã‚¤ãƒ«ã¯èª­ã¿è¾¼ã¿ã«æ™‚é–“ãŒã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™
        - Shapefileã¯é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«(.shx, .dbfç­‰)ãŒå¿…è¦ãªãŸã‚ã€ZIPãƒ•ã‚¡ã‚¤ãƒ«ã§ã®æä¾›ã‚’æ¨å¥¨ã—ã¾ã™
        
        ### æ³¨æ„äº‹é …
        - ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šãŒå¿…è¦ã§ã™
        - GISæ©Ÿèƒ½ã«ã¯GeoPandasãŒå¿…è¦ã§ã™
        - ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãƒªãƒã‚¸ãƒˆãƒªã®å ´åˆã¯é©åˆ‡ãªã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ãŒå¿…è¦ã§ã™
        - å¤§ããªGISãƒ•ã‚¡ã‚¤ãƒ«ã¯èª­ã¿è¾¼ã¿ã«æ™‚é–“ãŒã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™
        
        ### æ›´æ–°å±¥æ­´
        - **v39.0**: GitHubé€£æºå¼·åŒ–ã€ä½æ‰€ãƒ‡ãƒ¼ã‚¿è‡ªå‹•æ¤œç´¢ãƒ»èª­ã¿è¾¼ã¿æ©Ÿèƒ½è¿½åŠ 
        - **v33.0**: GISå¯¾å¿œã€Shapefileãƒ»KMLãƒ»ZIPèª­ã¿è¾¼ã¿æ©Ÿèƒ½è¿½åŠ 
        - **v12.0**: å›£ä½“ã‚³ãƒ¼ãƒ‰å¯¾å¿œã€æ²–ç¸„çœŒå„ªå…ˆè¡¨ç¤º
        - **v4.0**: Streamlitå¯¾å¿œã€ã‚·ãƒ³ãƒ—ãƒ«è¨­è¨ˆã«ç‰¹åŒ–
        - **v3.0**: GitHubå¯¾å¿œã€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–  
        - **v2.0**: GUIæ”¹å–„ã€ä¿å­˜æ©Ÿèƒ½è¿½åŠ   
        - **v1.0**: åˆæœŸãƒãƒ¼ã‚¸ãƒ§ãƒ³
        
        ---
        
        **ä½œæˆ**: AI Assistant  
        **ãƒ©ã‚¤ã‚»ãƒ³ã‚¹**: MIT  
        **ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ **: Streamlit Cloudå¯¾å¿œ  
        **GitHubé€£æº**: è‡ªå‹•ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢ãƒ»èª­ã¿è¾¼ã¿å¯¾å¿œ
        """)
        
        # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±
        st.header("ğŸ”§ ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±")
        
        import sys
        import platform
        
        system_info = {
            "Python ãƒãƒ¼ã‚¸ãƒ§ãƒ³": sys.version,
            "ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ": platform.platform(),
            "Streamlit ãƒãƒ¼ã‚¸ãƒ§ãƒ³": st.__version__,
            "GeoPandas": "åˆ©ç”¨å¯èƒ½" if GEOPANDAS_AVAILABLE else "åˆ©ç”¨ä¸å¯",
            "XMLå‡¦ç†": "åˆ©ç”¨å¯èƒ½" if XML_AVAILABLE else "åˆ©ç”¨ä¸å¯",
            "ç¾åœ¨æ™‚åˆ»": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        }
        
        for key, value in system_info.items():
            st.write(f"**{key}**: {value}")
        
        # å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®çŠ¶æ…‹
        st.header("ğŸ“¦ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªçŠ¶æ…‹")
        
        libraries = [
            ("streamlit", True),
            ("pandas", True),
            ("requests", True),
            ("geopandas", GEOPANDAS_AVAILABLE),
            ("fiona", GEOPANDAS_AVAILABLE),
            ("lxml", XML_AVAILABLE)
        ]
        
        for lib_name, available in libraries:
            status = "âœ… åˆ©ç”¨å¯èƒ½" if available else "âŒ æœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«"
            st.write(f"**{lib_name}**: {status}")
    
    def run(self):
        """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ"""
        # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ãƒšãƒ¼ã‚¸é¸æŠ
        st.sidebar.title("ğŸ›ï¸ ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³")
        
        pages = {
            "ğŸ¯ ãƒ¡ã‚¤ãƒ³": self.render_main_page,
            "ğŸ“Š ãƒ‡ãƒ¼ã‚¿ç®¡ç†": self.render_data_page,
            "â„¹ï¸ æƒ…å ±": self.render_about_page
        }
        
        selected_page = st.sidebar.selectbox("ãƒšãƒ¼ã‚¸ã‚’é¸æŠ", list(pages.keys()))
        
        # é¸æŠã•ã‚ŒãŸãƒšãƒ¼ã‚¸ã‚’è¡¨ç¤º
        pages[selected_page]()
        
        # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«åŸºæœ¬æƒ…å ±ã®ã¿è¡¨ç¤º
        if st.session_state.data_loaded and st.session_state.prefecture_data:
            st.sidebar.markdown("---")
            st.sidebar.header("ğŸ“Š ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿")
            st.sidebar.write("âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿æ¸ˆã¿")
            
            if st.session_state.selected_prefecture:
                st.sidebar.write(f"é¸æŠä¸­: {st.session_state.selected_prefecture}")
                if st.session_state.selected_city:
                    st.sidebar.write(f"å¸‚åŒºç”ºæ‘: {st.session_state.selected_city}")
                    if st.session_state.selected_oaza:
                        st.sidebar.write(f"å¤§å­—: {st.session_state.selected_oaza}")
                        if st.session_state.selected_chome:
                            st.sidebar.write(f"ä¸ç›®: {st.session_state.selected_chome}")
        
        # GISãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±
        if st.session_state.selected_file_path:
            st.sidebar.markdown("---")
            st.sidebar.header("ğŸ“„ ä½æ‰€ãƒ‡ãƒ¼ã‚¿")
            st.sidebar.write(f"ãƒ•ã‚¡ã‚¤ãƒ«: {os.path.basename(st.session_state.selected_file_path)}")
            if st.session_state.area_data:
                st.sidebar.write(f"å¤§å­—æ•°: {len(st.session_state.area_data)}")
        
        # ãƒ•ãƒƒã‚¿ãƒ¼
        st.sidebar.markdown("---")
        st.sidebar.markdown("**éƒ½é“åºœçœŒãƒ»å¸‚åŒºç”ºæ‘é¸æŠãƒ„ãƒ¼ãƒ« v39.0**")
        st.sidebar.markdown("Powered by Streamlit + GitHub API")

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    try:
        app = PrefectureCitySelectorGIS()
        app.run()
    except Exception as e:
        st.error(f"ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼: {str(e)}")
        st.info("ãƒšãƒ¼ã‚¸ã‚’å†èª­ã¿è¾¼ã¿ã—ã¦ãã ã•ã„ã€‚")

if __name__ == "__main__":
    main()é¸æŠã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’ä½œæˆ
                                    file_options = ["é¸æŠã—ã¦ãã ã•ã„"]
                                    file_mapping = {}
                                    
                                    # å€‹åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«
                                    for f in files:
                                        base_name = os.path.basename(f)
                                        file_options.append(f"ğŸ“„ {base_name}")
                                        file_mapping[f"ğŸ“„ {base_name}"] = f
                                    
                                    # Shapefileã‚»ãƒƒãƒˆ
                                    for base_name, file_list in shapefile_sets.items():
                                        set_name = f"ğŸ—ºï¸ {os.path.basename(base_name)}.shp (ã‚»ãƒƒãƒˆ)"
                                        file_options.append(set_name)
                                        # Shapefileã‚»ãƒƒãƒˆã®å ´åˆã¯.shpãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä»£è¡¨ã¨ã—ã¦é¸æŠ
                                        shp_file = next((f for f in file_list if f.endswith('.shp')), file_list[0])
                                        file_mapping[set_name] = shp_file
                                    
                                    # ãƒ•ã‚¡ã‚¤ãƒ«