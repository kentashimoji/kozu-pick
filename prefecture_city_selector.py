#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
éƒ½é“åºœçœŒãƒ»å¸‚åŒºç”ºæ‘é¸æŠãƒ„ãƒ¼ãƒ« v4.0 (Streamlitç‰ˆ)
GitHub Excelãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä½œæˆ

å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒª:
pip install streamlit pandas openpyxl requests plotly

å®Ÿè¡Œæ–¹æ³•:
streamlit run prefecture_city_selector_streamlit.py
"""

import streamlit as st
import pandas as pd
import requests
from io import BytesIO
import json
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
import base64

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="éƒ½é“åºœçœŒãƒ»å¸‚åŒºç”ºæ‘é¸æŠãƒ„ãƒ¼ãƒ« v4.0",
    page_icon="ğŸ›ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

class PrefectureCitySelectorWeb:
    def __init__(self):
        self.init_session_state()
    
    def init_session_state(self):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’åˆæœŸåŒ–"""
        if 'prefecture_data' not in st.session_state:
            st.session_state.prefecture_data = {}
        if 'data_loaded' not in st.session_state:
            st.session_state.data_loaded = False
        if 'current_url' not in st.session_state:
            st.session_state.current_url = ""
        if 'selected_prefecture' not in st.session_state:
            st.session_state.selected_prefecture = ""
        if 'selected_city' not in st.session_state:
            st.session_state.selected_city = ""
    
    def load_data_from_github(self, url):
        """GitHubã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        try:
            if not url:
                st.error("URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
                return False
                
            if "raw.githubusercontent.com" not in url:
                st.warning("GitHub Raw URLã§ã¯ãªã„ã‚ˆã†ã§ã™ã€‚æ­£ã—ã„URLã¯ 'raw.githubusercontent.com' ã‚’å«ã‚“ã§ã„ã¾ã™ã€‚")
            
            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã‚’è¡¨ç¤º
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            status_text.text("ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ã„ã¾ã™...")
            progress_bar.progress(25)
            
            headers = {'User-Agent': 'PrefectureCitySelector/4.0'}
            response = requests.get(url, headers=headers, timeout=30)
            response.raise_for_status()
            
            progress_bar.progress(50)
            status_text.text("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æã—ã¦ã„ã¾ã™...")
            
            # ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã‚’åˆ¤å®šã—ã¦èª­ã¿è¾¼ã¿
            if url.lower().endswith('.csv'):
                df = pd.read_csv(BytesIO(response.content), encoding='utf-8-sig')
            else:
                excel_data = BytesIO(response.content)
                df = pd.read_excel(excel_data)
            
            progress_bar.progress(75)
            status_text.text("ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã—ã¦ã„ã¾ã™...")
            
            # ãƒ‡ãƒ¼ã‚¿ã‚’æ•´ç†
            prefecture_data = {}
            prefecture_cols = [col for col in df.columns if 'éƒ½é“åºœçœŒ' in col and 'æ¼¢å­—' in col]
            city_cols = [col for col in df.columns if 'å¸‚åŒºç”ºæ‘' in col and 'æ¼¢å­—' in col]
            
            if not prefecture_cols or not city_cols:
                st.error(f"é©åˆ‡ãªåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚åˆ©ç”¨å¯èƒ½ãªåˆ—: {list(df.columns)}")
                return False
            
            prefecture_col = prefecture_cols[0]
            city_col = city_cols[0]
            
            for _, row in df.iterrows():
                prefecture = row.get(prefecture_col)
                city = row.get(city_col)
                
                if pd.notna(prefecture):
                    if prefecture not in prefecture_data:
                        prefecture_data[prefecture] = set()
                    
                    if pd.notna(city):
                        prefecture_data[prefecture].add(city)
            
            # Setã‚’Listã«å¤‰æ›ã—ã¦ã‚½ãƒ¼ãƒˆ
            for prefecture in prefecture_data:
                prefecture_data[prefecture] = sorted(list(prefecture_data[prefecture]))
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’æ›´æ–°
            st.session_state.prefecture_data = prefecture_data
            st.session_state.data_loaded = True
            st.session_state.current_url = url
            
            progress_bar.progress(100)
            status_text.text("âœ… ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
            
            # çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º
            total_prefectures = len(prefecture_data)
            total_cities = sum(len(cities) for cities in prefecture_data.values())
            
            st.success(f"ğŸ“Š èª­ã¿è¾¼ã¿å®Œäº†: {total_prefectures}éƒ½é“åºœçœŒ, {total_cities}å¸‚åŒºç”ºæ‘")
            
            return True
            
        except requests.RequestException as e:
            st.error(f"ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return False
        except Exception as e:
            st.error(f"ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
            return False
    
    def create_download_link(self, data, filename, file_type="json"):
        """ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒªãƒ³ã‚¯ã‚’ä½œæˆ"""
        if file_type == "json":
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
            save_data = {
                "metadata": {
                    "version": "4.0",
                    "created_at": datetime.now().isoformat(),
                    "source_url": st.session_state.current_url,
                    "total_prefectures": len(data),
                    "total_cities": sum(len(cities) for cities in data.values())
                },
                "data": data
            }
            content = json.dumps(save_data, ensure_ascii=False, indent=2)
            mime_type = "application/json"
        
        elif file_type == "csv":
            rows = []
            for prefecture, cities in data.items():
                for city in cities:
                    rows.append([prefecture, city, f"{prefecture}{city}"])
            
            df = pd.DataFrame(rows, columns=['éƒ½é“åºœçœŒ', 'å¸‚åŒºç”ºæ‘', 'å®Œå…¨ä½æ‰€'])
            content = df.to_csv(index=False, encoding='utf-8-sig')
            mime_type = "text/csv"
        
        b64 = base64.b64encode(content.encode('utf-8-sig')).decode()
        href = f'<a href="data:{mime_type};base64,{b64}" download="{filename}">ğŸ“¥ {filename}ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰</a>'
        return href
    
    def render_main_page(self):
        """ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ã‚’æç”»"""
        st.title("ğŸ›ï¸ éƒ½é“åºœçœŒãƒ»å¸‚åŒºç”ºæ‘é¸æŠãƒ„ãƒ¼ãƒ« v4.0")
        
        col1, col2, col3 = st.columns([2, 1, 1])
        with col1:
            st.markdown("**GitHub Excelãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä½œæˆ**")
        with col2:
            st.metric("ãƒãƒ¼ã‚¸ãƒ§ãƒ³", "4.0")
        with col3:
            st.metric("ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ", "Streamlit")
        
        st.markdown("---")
        
        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚»ã‚¯ã‚·ãƒ§ãƒ³
        st.header("ğŸ“¡ ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹è¨­å®š")
        
        default_url = "git@github.com:kentashimoji/kozu-pick.git/000925835.xlsx"
        url = st.text_input(
            "GitHub Excelãƒ•ã‚¡ã‚¤ãƒ«URL:",
            value=st.session_state.current_url or default_url,
            help="GitHubã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ãã€'Raw'ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ãŸæ™‚ã®URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"
        )
        
        col1, col2, col3 = st.columns([1, 1, 2])
        with col1:
            if st.button("ğŸ”„ ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿", type="primary"):
                self.load_data_from_github(url)
        
        with col2:
            if st.button("ğŸ—‘ï¸ ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢"):
                st.session_state.prefecture_data = {}
                st.session_state.data_loaded = False
                st.session_state.selected_prefecture = ""
                st.session_state.selected_city = ""
                st.success("ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ")
                st.experimental_rerun()
        
        # ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã‚‹å ´åˆã®é¸æŠUI
        if st.session_state.data_loaded and st.session_state.prefecture_data:
            st.markdown("---")
            st.header("ğŸ¯ åœ°åŸŸé¸æŠ")
            
            col1, col2 = st.columns(2)
            
            with col1:
                prefectures = sorted(st.session_state.prefecture_data.keys())
                prefecture_options = [f"{p} ({len(st.session_state.prefecture_data[p])}å¸‚åŒºç”ºæ‘)" 
                                    for p in prefectures]
                
                selected_prefecture_display = st.selectbox(
                    "éƒ½é“åºœçœŒã‚’é¸æŠã—ã¦ãã ã•ã„:",
                    ["é¸æŠã—ã¦ãã ã•ã„"] + prefecture_options,
                    key="prefecture_select"
                )
                
                if selected_prefecture_display != "é¸æŠã—ã¦ãã ã•ã„":
                    prefecture_name = selected_prefecture_display.split(' (')[0]
                    st.session_state.selected_prefecture = prefecture_name
            
            with col2:
                if st.session_state.selected_prefecture:
                    cities = st.session_state.prefecture_data[st.session_state.selected_prefecture]
                    
                    selected_city = st.selectbox(
                        "å¸‚åŒºç”ºæ‘ã‚’é¸æŠã—ã¦ãã ã•ã„:",
                        ["é¸æŠã—ã¦ãã ã•ã„"] + cities,
                        key="city_select"
                    )
                    
                    if selected_city != "é¸æŠã—ã¦ãã ã•ã„":
                        st.session_state.selected_city = selected_city
                else:
                    st.selectbox(
                        "å¸‚åŒºç”ºæ‘ã‚’é¸æŠã—ã¦ãã ã•ã„:",
                        ["ã¾ãšéƒ½é“åºœçœŒã‚’é¸æŠã—ã¦ãã ã•ã„"],
                        disabled=True
                    )
            
            # é¸æŠçµæœã®è¡¨ç¤º
            if st.session_state.selected_prefecture and st.session_state.selected_city:
                st.markdown("---")
                st.header("ğŸ“ é¸æŠçµæœ")
                
                result_data = {
                    "éƒ½é“åºœçœŒ": st.session_state.selected_prefecture,
                    "å¸‚åŒºç”ºæ‘": st.session_state.selected_city,
                    "å®Œå…¨ãªä½æ‰€": f"{st.session_state.selected_prefecture}{st.session_state.selected_city}",
                    "é¸æŠæ—¥æ™‚": datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S'),
                    "ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹": st.session_state.current_url[:60] + "..." if len(st.session_state.current_url) > 60 else st.session_state.current_url
                }
                
                col1, col2 = st.columns([2, 1])
                
                with col1:
                    for key, value in result_data.items():
                        st.write(f"**{key}:** {value}")
                
                with col2:
                    if st.button("ğŸ“‹ çµæœã‚’ã‚³ãƒ”ãƒ¼"):
                        result_text = "\n".join([f"{k}: {v}" for k, v in result_data.items()])
                        st.code(result_text)
                        st.success("çµæœã‚’è¡¨ç¤ºã—ã¾ã—ãŸã€‚ä¸Šè¨˜ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚³ãƒ”ãƒ¼ã—ã¦ãã ã•ã„ã€‚")
    
    def render_data_page(self):
        """ãƒ‡ãƒ¼ã‚¿ç®¡ç†ãƒšãƒ¼ã‚¸ã‚’æç”»"""
        st.title("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ç®¡ç†")
        
        if not st.session_state.data_loaded or not st.session_state.prefecture_data:
            st.warning("ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ã§ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚")
            return
        
        # ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ
        st.header("ğŸ“ˆ ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ")
        
        total_prefectures = len(st.session_state.prefecture_data)
        total_cities = sum(len(cities) for cities in st.session_state.prefecture_data.values())
        avg_cities = total_cities / total_prefectures if total_prefectures > 0 else 0
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("éƒ½é“åºœçœŒæ•°", total_prefectures)
        with col2:
            st.metric("ç·å¸‚åŒºç”ºæ‘æ•°", total_cities)
        with col3:
            st.metric("å¹³å‡å¸‚åŒºç”ºæ‘æ•°", f"{avg_cities:.1f}")
        with col4:
            st.metric("ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹", "GitHub" if st.session_state.current_url else "æœªè¨­å®š")
        
        # ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–
        st.header("ğŸ“Š ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–")
        
        # éƒ½é“åºœçœŒåˆ¥å¸‚åŒºç”ºæ‘æ•°ã®æ£’ã‚°ãƒ©ãƒ•
        prefecture_counts = {p: len(cities) for p, cities in st.session_state.prefecture_data.items()}
        df_counts = pd.DataFrame(list(prefecture_counts.items()), columns=['éƒ½é“åºœçœŒ', 'å¸‚åŒºç”ºæ‘æ•°'])
        df_counts = df_counts.sort_values('å¸‚åŒºç”ºæ‘æ•°', ascending=False)
        
        fig = px.bar(df_counts, x='éƒ½é“åºœçœŒ', y='å¸‚åŒºç”ºæ‘æ•°', 
                     title='éƒ½é“åºœçœŒåˆ¥å¸‚åŒºç”ºæ‘æ•°',
                     color='å¸‚åŒºç”ºæ‘æ•°',
                     color_continuous_scale='viridis')
        fig.update_layout(xaxis_tickangle=-45, height=500)
        st.plotly_chart(fig, use_container_width=True)
        
        # ä¸Šä½10éƒ½é“åºœçœŒ
        st.subheader("ğŸ“‹ å¸‚åŒºç”ºæ‘æ•°ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆä¸Šä½10ï¼‰")
        top10 = df_counts.head(10)
        
        for i, (_, row) in enumerate(top10.iterrows(), 1):
            col1, col2, col3 = st.columns([1, 3, 1])
            with col1:
                st.write(f"**{i}ä½**")
            with col2:
                st.write(f"{row['éƒ½é“åºœçœŒ']}")
            with col3:
                st.write(f"{row['å¸‚åŒºç”ºæ‘æ•°']}å¸‚åŒºç”ºæ‘")
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        st.header("ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("ğŸ“„ JSONå½¢å¼ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"):
                filename = f"prefecture_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
                download_link = self.create_download_link(
                    st.session_state.prefecture_data, filename, "json"
                )
                st.markdown(download_link, unsafe_allow_html=True)
        
        with col2:
            if st.button("ğŸ“Š CSVå½¢å¼ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"):
                filename = f"prefecture_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
                download_link = self.create_download_link(
                    st.session_state.prefecture_data, filename, "csv"
                )
                st.markdown(download_link, unsafe_allow_html=True)
        
        # è©³ç´°ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º
        st.header("ğŸ” è©³ç´°ãƒ‡ãƒ¼ã‚¿")
        
        if st.checkbox("å…¨ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º"):
            all_data = []
            for prefecture, cities in st.session_state.prefecture_data.items():
                for city in cities:
                    all_data.append({
                        'éƒ½é“åºœçœŒ': prefecture,
                        'å¸‚åŒºç”ºæ‘': city,
                        'å®Œå…¨ä½æ‰€': f"{prefecture}{city}"
                    })
            
            df_all = pd.DataFrame(all_data)
            st.dataframe(df_all, use_container_width=True)
            
            st.info(f"ç·ä»¶æ•°: {len(df_all)}ä»¶")
    
    def render_about_page(self):
        """æƒ…å ±ãƒšãƒ¼ã‚¸ã‚’æç”»"""
        st.title("â„¹ï¸ ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æƒ…å ±")
        
        st.markdown("""
        ## ğŸ›ï¸ éƒ½é“åºœçœŒãƒ»å¸‚åŒºç”ºæ‘é¸æŠãƒ„ãƒ¼ãƒ« v4.0
        
        ### æ¦‚è¦
        GitHubã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸExcelãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ—¥æœ¬ã®éƒ½é“åºœçœŒãƒ»å¸‚åŒºç”ºæ‘ãƒ‡ãƒ¼ã‚¿ã‚’
        èª­ã¿è¾¼ã¿ã€éšå±¤çš„ãªé¸æŠã‚’å¯èƒ½ã«ã™ã‚‹Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã™ã€‚
        
        ### ä¸»ãªæ©Ÿèƒ½
        âœ… **GitHubå¯¾å¿œ**: GitHubä¸Šã®Excelãƒ•ã‚¡ã‚¤ãƒ«ã®ç›´æ¥èª­ã¿è¾¼ã¿  
        âœ… **éšå±¤é¸æŠ**: éƒ½é“åºœçœŒé¸æŠã«ã‚ˆã‚‹å¸‚åŒºç”ºæ‘ã®çµã‚Šè¾¼ã¿  
        âœ… **ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–**: çµ±è¨ˆæƒ…å ±ã¨ã‚°ãƒ©ãƒ•è¡¨ç¤º  
        âœ… **ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ**: JSON/CSVå½¢å¼ã§ã®ä¿å­˜  
        âœ… **ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–**: ãƒ¢ãƒã‚¤ãƒ«ãƒ»ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—å¯¾å¿œ  
        âœ… **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ **: é¸æŠçµæœã®å³æ™‚è¡¨ç¤º  
        
        ### å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒª
        ```bash
        pip install streamlit pandas openpyxl requests plotly
        ```
        
        ### å®Ÿè¡Œæ–¹æ³•
        ```bash
        streamlit run prefecture_city_selector_streamlit.py
        ```
        
        ### GitHub Raw URLã®å–å¾—æ–¹æ³•
        1. GitHubã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã
        2. ã€ŒRawã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯  
        3. ãƒ–ãƒ©ã‚¦ã‚¶ã®ã‚¢ãƒ‰ãƒ¬ã‚¹ãƒãƒ¼ã‹ã‚‰URLã‚’ã‚³ãƒ”ãƒ¼
        
        ### å¯¾å¿œãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼
        - Excel (.xlsx, .xls)
        - CSV (.csv)
        
        ### æ³¨æ„äº‹é …
        - ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šãŒå¿…è¦ã§ã™
        - ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãƒªãƒã‚¸ãƒˆãƒªã®å ´åˆã¯é©åˆ‡ãªã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ãŒå¿…è¦ã§ã™
        - ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãã„å ´åˆã¯èª­ã¿è¾¼ã¿ã«æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™
        
        ### æ›´æ–°å±¥æ­´
        - **v4.0**: Streamlitå¯¾å¿œã€ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–æ©Ÿèƒ½è¿½åŠ 
        - **v3.0**: GitHubå¯¾å¿œã€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–  
        - **v2.0**: GUIæ”¹å–„ã€ä¿å­˜æ©Ÿèƒ½è¿½åŠ   
        - **v1.0**: åˆæœŸãƒãƒ¼ã‚¸ãƒ§ãƒ³  
        
        ---
        
        **ä½œæˆ**: AI Assistant  
        **ãƒ©ã‚¤ã‚»ãƒ³ã‚¹**: MIT  
        **ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ **: Streamlit Cloudå¯¾å¿œ
        """)
        
        # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±
        st.header("ğŸ”§ ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±")
        
        import sys
        import platform
        
        system_info = {
            "Python ãƒãƒ¼ã‚¸ãƒ§ãƒ³": sys.version,
            "ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ": platform.platform(),
            "Streamlit ãƒãƒ¼ã‚¸ãƒ§ãƒ³": st.__version__,
            "ç¾åœ¨æ™‚åˆ»": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        }
        
        for key, value in system_info.items():
            st.write(f"**{key}**: {value}")
    
    def run(self):
        """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ"""
        # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ãƒšãƒ¼ã‚¸é¸æŠ
        st.sidebar.title("ğŸ›ï¸ ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³")
        
        pages = {
            "ğŸ¯ ãƒ¡ã‚¤ãƒ³": self.render_main_page,
            "ğŸ“Š ãƒ‡ãƒ¼ã‚¿ç®¡ç†": self.render_data_page,
            "â„¹ï¸ æƒ…å ±": self.render_about_page
        }
        
        selected_page = st.sidebar.selectbox("ãƒšãƒ¼ã‚¸ã‚’é¸æŠ", list(pages.keys()))
        
        # é¸æŠã•ã‚ŒãŸãƒšãƒ¼ã‚¸ã‚’è¡¨ç¤º
        pages[selected_page]()
        
        # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«çµ±è¨ˆæƒ…å ±è¡¨ç¤º
        if st.session_state.data_loaded and st.session_state.prefecture_data:
            st.sidebar.markdown("---")
            st.sidebar.header("ğŸ“Š ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿")
            st.sidebar.write(f"éƒ½é“åºœçœŒæ•°: {len(st.session_state.prefecture_data)}")
            st.sidebar.write(f"å¸‚åŒºç”ºæ‘æ•°: {sum(len(cities) for cities in st.session_state.prefecture_data.values())}")
            
            if st.session_state.selected_prefecture:
                st.sidebar.write(f"é¸æŠä¸­: {st.session_state.selected_prefecture}")
                if st.session_state.selected_city:
                    st.sidebar.write(f"å¸‚åŒºç”ºæ‘: {st.session_state.selected_city}")
        
        # ãƒ•ãƒƒã‚¿ãƒ¼
        st.sidebar.markdown("---")
        st.sidebar.markdown("**éƒ½é“åºœçœŒãƒ»å¸‚åŒºç”ºæ‘é¸æŠãƒ„ãƒ¼ãƒ« v4.0**")
        st.sidebar.markdown("Powered by Streamlit")

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    try:
        app = PrefectureCitySelectorWeb()
        app.run()
    except Exception as e:
        st.error(f"ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼: {str(e)}")
        st.info("ãƒšãƒ¼ã‚¸ã‚’å†èª­ã¿è¾¼ã¿ã—ã¦ãã ã•ã„ã€‚")

if __name__ == "__main__":
    main()
